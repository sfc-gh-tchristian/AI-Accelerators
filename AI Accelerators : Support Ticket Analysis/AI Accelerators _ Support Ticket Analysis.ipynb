{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab10f733-91d9-42b6-a5b1-8f21148e7e74",
   "metadata": {
    "collapsed": false,
    "name": "intro"
   },
   "source": [
    "# ‚ú® Support Ticket Analysis powered by Snowflake Cortex\n",
    "\n",
    "## üéØ Purpose\n",
    "This notebook demonstrates how to analyse customer support tickets using Snowflake's Cortex AI capabilities to identify trends, sentiment patterns, and critical issues that require immediate attention.\n",
    "\n",
    "## üí° Why do this?\n",
    "- üîç **Early Issue Detection**: Identify system-wide problems and outages through pattern recognition\n",
    "- üòä **Sentiment Analysis**: Track customer satisfaction across multiple dimensions (brand, product, support)\n",
    "- ‚ö° **Automated Escalation**: Use AI to determine which tickets require immediate escalation\n",
    "- üìà **Trend Analysis**: Visualize ticket volumes and sentiment patterns over time\n",
    "- üöÄ **Efficient Support**: Quickly find similar cases using semantic search capabilities\n",
    "\n",
    "## üõ†Ô∏è Solution Components\n",
    "Note: a combination of SQL & Python will be used for the same outcome. Pick your preferred route!\n",
    "\n",
    "1. üìä **Data Visualisation & EDA**\n",
    "   - Use in-built streamlit functionality to see:\n",
    "   - Weekly ticket volume by priority\n",
    "   - Sentiment trends over time\n",
    "\n",
    "2. ü§ñ **AI-Powered Analysis**\n",
    "   - Issue summarization using `AI_AGG`\n",
    "   - Automated outage detection with `AI_FILTER`\n",
    "   - Multi-dimensional sentiment analysis with `AI_SENTIMENT`\n",
    "\n",
    "3. ‚öôÔ∏è **Automated Pipeline**\n",
    "   - CDC for automated ticket processing\n",
    "   - Scheduled updates for search indices\n",
    "\n",
    "4. üéØ **Accurate Retrieval**\n",
    "   - Semantic search for case similarity matching\n",
    "   - Quantitative analysis through semantic views \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "imports"
   },
   "outputs": [],
   "source": [
    "# If you're running this on the warehouse runtime, please ensure the following packages are included (see top right)\n",
    "# snowflake-ml-python\n",
    "# snowflake\n",
    "#... and that's it!\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "from datetime import datetime\n",
    "\n",
    "#notebooks allow for easy context calling - now we have a permissions/role aligned session in flight\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf86c94a-259d-416d-886c-ab73633de327",
   "metadata": {
    "language": "python",
    "name": "table_loc_v"
   },
   "outputs": [],
   "source": [
    "# If you'd like to swap to your data - start by defining the table location here:\n",
    "table_loc = 'AI_SOL.SUPPORT.RAW_SUPPORT_TICKETS'\n",
    "\n",
    "## {{}} allows us to reference the table name - even in SQL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "sql",
    "name": "data_preview"
   },
   "outputs": [],
   "source": [
    "-- The dummy data we'll be using is Zendesk style data. \n",
    "-- We're particularly interested in the TICKET_DESCRIPTION column.\n",
    "-- NOTE! You can use CTRL+F to quickly replace references to your column.\n",
    "SELECT * FROM {{table_loc}} LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67b1fb6-dcd0-418e-acdb-adb9a5a5aeca",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "streamlit_eda"
   },
   "outputs": [],
   "source": [
    "## Let's perform some basic exploration using Streamlit visuals and altair\n",
    "## NOTE! If you've swapped to your data, remember to select the appropriate columns\n",
    "\n",
    "# First, let's reference our table\n",
    "df = session.table(table_loc).to_pandas() \n",
    "\n",
    "# Create a form to contain all selection widgets\n",
    "with st.form(\"visualization_options\"):\n",
    "    # Get all datetime columns\n",
    "    date_columns = df.select_dtypes(include=['datetime64']).columns.tolist()\n",
    "    date_field = st.selectbox('Select Date Field', date_columns)\n",
    "\n",
    "    # Get categorical columns (object type)\n",
    "    categorical_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    category_field = st.selectbox('Select Category Field for Trend Analysis', categorical_columns)\n",
    "\n",
    "    # Submit button\n",
    "    submitted = st.form_submit_button(\"Update Visualizations\")\n",
    "\n",
    "if submitted or True:  # Show default visualization on first load\n",
    "    # Convert selected date to datetime if needed\n",
    "    df[date_field] = pd.to_datetime(df[date_field])\n",
    "\n",
    "    # Display date range and record count\n",
    "    st.write(\"Date range in data:\", \n",
    "             df[date_field].min().strftime('%Y-%m-%d'), \n",
    "             \"to\", \n",
    "             df[date_field].max().strftime('%Y-%m-%d'))\n",
    "    st.write(\"Number of records:\", len(df))\n",
    "\n",
    "    # Create trend chart by selected category\n",
    "    trend_by_category = alt.Chart(df).mark_line(opacity=0.6).encode(\n",
    "        x=alt.X(f'{date_field}:T', \n",
    "                title='Week Starting',\n",
    "                timeUnit='yearweek',  \n",
    "                axis=alt.Axis(format='%Y-%m-%d')\n",
    "               ),\n",
    "        y=alt.Y('count():Q', title='Number of Records'),\n",
    "        color=alt.Color(f'{category_field}:N', title=category_field),\n",
    "        tooltip=[\n",
    "            alt.Tooltip(f'{date_field}:T', title='Week Starting', timeUnit='yearweek', format='%Y-%m-%d'),\n",
    "            alt.Tooltip(f'{category_field}:N'),\n",
    "            alt.Tooltip('count():Q', title='Count')\n",
    "        ]\n",
    "    ).properties(\n",
    "        title=f'Weekly Trends by {category_field}',\n",
    "        height=300\n",
    "    )\n",
    "\n",
    "    # Display chart\n",
    "    st.altair_chart(trend_by_category, use_container_width=True)\n",
    "\n",
    "    # Show distribution of categories\n",
    "    distribution = df[category_field].value_counts()\n",
    "    st.write(f\"\\nDistribution of {category_field}:\")\n",
    "    st.bar_chart(distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5197510-7e6c-42fc-9417-2ce742511cca",
   "metadata": {
    "collapsed": false,
    "name": "AI_AGG"
   },
   "source": [
    "In the dummy dataset, we have considerably more negative events happening around w/c 11th May. Let's use Cortex and AISQL to dig into those values.\n",
    "\n",
    "We'll start with `AI_AGG` - this allows us to ask a singular prompt across multiple rows of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6857d51-f933-4722-9785-a47dac8df1c5",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "agg_func_python"
   },
   "outputs": [],
   "source": [
    "# Although we loving call it AISQL - \n",
    "# you can either use Python or SQL (see next cell!)\n",
    "\n",
    "from snowflake.snowpark.functions import ai_agg, col, date_trunc\n",
    "\n",
    "df = session.table(table_loc)\n",
    "\n",
    "# Filter for the week with the spike in behaviour\n",
    "# Then, based on those tickets, summarise the findings\n",
    "result = df.filter(\n",
    "    date_trunc('week', col('SUBMIT_DATE')) == '2025-05-12'\n",
    ").agg(\n",
    "    ai_agg(\n",
    "        col('TICKET_DESCRIPTION'),\n",
    "        'What are the top reoccuring issues across these support tickets? Highlight particular trends that would cause negative sentiment issues.'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Display the result\n",
    "st.write(result.collect()[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167e491f-e18d-45bb-af2e-a036c3d21ae4",
   "metadata": {
    "language": "sql",
    "name": "agg_func_sql"
   },
   "outputs": [],
   "source": [
    "-- This behaviour acts the same, pick and choose based on your preferred language!\n",
    "SELECT \n",
    "AI_AGG(ticket_description, \n",
    "'What are the top reoccuring issues across these support tickets? Highlight particular trends that would cause negative sentiment issues. '\n",
    ")\n",
    "FROM {{table_loc}}\n",
    "WHERE DATE_TRUNC('week',SUBMIT_DATE)='2025-05-12';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d689c567-825d-4e1e-80c8-6a89cc114c94",
   "metadata": {
    "collapsed": false,
    "name": "AI_FILTER"
   },
   "source": [
    "In our dummy data, widespread outages appear to be the significant cause for the rise in negative sentiment and overall spike in requests.\n",
    "\n",
    "Let's use `AI_FILTER` to quickly find customer tickets that mention a system outage as a whole.\n",
    "\n",
    "Remember, we don't always say what we mean! Using `AI_FILTER` allows us to capture the literal phrase \"outage\" but also instances such as \"everything has gone down\" and \"nothing works\".\n",
    "\n",
    "We can even use it to apply a degree of business logic - for example \"does this issue require escalation?\". You may want to provide more detailed guidance in a real life scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e22b39-72dc-46c0-bd16-aff6e9e26221",
   "metadata": {
    "language": "sql",
    "name": "filter_func"
   },
   "outputs": [],
   "source": [
    "-- We can use AI_FILTER to both narrow down our dataset as well as act as a column boolean.\n",
    "-- Unsurprisingly in this case, the vast majority of system outage emails results in a recommendation to escalate (with zero guidance to the LLM)\n",
    "\n",
    "SELECT \n",
    "TICKET_ID,\n",
    "AI_FILTER(PROMPT('Does this ticket require escalation? {0}', TICKET_DESCRIPTION)) as escalate,\n",
    "TICKET_DESCRIPTION\n",
    "FROM {{table_loc}}\n",
    "WHERE\n",
    "AI_FILTER(PROMPT('Does this ticket mention a system outage? {0}', TICKET_DESCRIPTION))\n",
    "AND\n",
    "DATE_TRUNC('week',SUBMIT_DATE)='2025-05-12';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca39ad1-e513-401b-b410-b9fd5878e514",
   "metadata": {
    "collapsed": false,
    "name": "AI_SENTIMENT"
   },
   "source": [
    "Many products capture a basic sentiment score - but rarely tell the full picture. \n",
    "\n",
    "`AI_SENTIMENT` allows for that breadth of view across multiple key factors. As standard, it'll always provide you with the overall view - but equally allow you to drill into the nuance behind that.\n",
    "\n",
    "For example - a review may be positive overall, but could express concern towards the support team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945b4c14-f484-4699-81df-75e320636140",
   "metadata": {
    "language": "sql",
    "name": "ai_sent_func"
   },
   "outputs": [],
   "source": [
    "SELECT ticket_id,\n",
    "AI_SENTIMENT(ticket_description,\n",
    "    ['brand', 'product', 'customer support']) as sentiment_json,\n",
    "        sentiment_json:categories[0]:sentiment::STRING AS overall_sentiment,\n",
    "        sentiment_json:categories[1]:sentiment::STRING as brand_sentiment,\n",
    "        sentiment_json:categories[2]:sentiment::STRING as product_sentiment,\n",
    "        sentiment_json:categories[3]:sentiment::STRING as customer_support_sentiment,\n",
    "        ticket_description\n",
    "FROM \n",
    "{{table_loc}}\n",
    "WHERE\n",
    "DATE_TRUNC('week',SUBMIT_DATE)='2025-05-12';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d4822e",
   "metadata": {},
   "source": [
    "# üîÑ Automated Ticket Processing Pipeline\n",
    "\n",
    "Now we'll create an automated pipeline using Dynamic Tables to process support tickets and extract key metadata. This pipeline continuously processes new tickets as they arrive, extracting structured information using AI.\n",
    "\n",
    "This approach replaces the traditional streams and tasks pattern with a more declarative, managed solution that Snowflake automatically orchestrates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce73f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Create automated ticket processing pipeline with Dynamic Table\n",
    "-- This processes support tickets and extracts key metadata automatically as new tickets arrive\n",
    "-- Target lag controls how fresh the data is (adjust based on your needs)\n",
    "\n",
    "CREATE OR REPLACE DYNAMIC TABLE SUPPORT_TICKET_METADATA\n",
    "  TARGET_LAG = '1 hour'\n",
    "  WAREHOUSE = tc_wh  -- Update to your warehouse\n",
    "  AS\n",
    "WITH ticket_processing AS (\n",
    "    SELECT \n",
    "        t.TICKET_ID as ticket_id,\n",
    "        t.TICKET_DESCRIPTION as description,\n",
    "        t.SUBMIT_DATE as submit_date,\n",
    "        t.PRIORITY as original_priority,\n",
    "        t.STATUS as status,\n",
    "        t.CUSTOMER_TIER as customer_tier,\n",
    "        t.CHANNEL as channel,\n",
    "        \n",
    "        -- Extract ticket metadata using AI_COMPLETE with structured output\n",
    "        AI_COMPLETE(\n",
    "            model => 'claude-4-sonnet',\n",
    "            prompt => 'You are an expert in customer support ticket analysis. Analyze this support ticket and extract key information. Only extract information explicitly mentioned in the ticket description.' ||\n",
    "                      '\\n\\nSUPPORT TICKET:\\n' || \n",
    "                      'Ticket ID: ' || t.TICKET_ID || '\\n' ||\n",
    "                      'Description: ' || t.TICKET_DESCRIPTION || '\\n' ||\n",
    "                      'Priority: ' || t.PRIORITY || '\\n' ||\n",
    "                      'Customer Tier: ' || t.CUSTOMER_TIER || '\\n' ||\n",
    "                      '\\nEND OF TICKET DATA\\n\\n',\n",
    "            response_format => {\n",
    "                'type': 'json',\n",
    "                'schema': {\n",
    "                    'type': 'object',\n",
    "                    'properties': {\n",
    "                        'issue_type': {\n",
    "                            'type': 'string',\n",
    "                            'description': 'The primary type of issue (e.g., Technical Issue, Billing Question, Feature Request, Bug Report)'\n",
    "                        },\n",
    "                        'product_area': {\n",
    "                            'type': 'string',\n",
    "                            'description': 'The specific product or service area affected (e.g., Mobile App, Web Platform, API, Billing System)'\n",
    "                        },\n",
    "                        'root_cause': {\n",
    "                            'type': 'string',\n",
    "                            'description': 'The apparent root cause or source of the issue if mentioned'\n",
    "                        },\n",
    "                        'customer_impact': {\n",
    "                            'type': 'string',\n",
    "                            'description': 'Description of how the issue impacts the customer (e.g., Cannot access account, Service unavailable, Billing error)'\n",
    "                        },\n",
    "                        'requires_escalation': {\n",
    "                            'type': 'boolean',\n",
    "                            'description': 'TRUE if the issue requires immediate escalation based on severity or customer impact'\n",
    "                        },\n",
    "                        'system_outage': {\n",
    "                            'type': 'boolean',\n",
    "                            'description': 'TRUE if the ticket mentions a system-wide outage or widespread service disruption'\n",
    "                        },\n",
    "                        'mentions_competitor': {\n",
    "                            'type': 'boolean',\n",
    "                            'description': 'TRUE if the customer mentions a competitor or considering switching'\n",
    "                        },\n",
    "                        'ticket_summary': {\n",
    "                            'type': 'string',\n",
    "                            'description': 'Brief 1-sentence summary of the ticket and customer request'\n",
    "                        }\n",
    "                    },\n",
    "                    'required': ['issue_type', 'product_area', 'customer_impact', 'ticket_summary'],\n",
    "                    'additionalProperties': false\n",
    "                }\n",
    "            }\n",
    "        ) as metadata_json,\n",
    "        \n",
    "        -- Classify urgency level\n",
    "        AI_CLASSIFY(\n",
    "            t.TICKET_DESCRIPTION,\n",
    "            [\n",
    "                {'label': 'Critical', 'description': 'Service completely unavailable, data loss, security breach, customer threatening to leave'},\n",
    "                {'label': 'High', 'description': 'Major functionality broken, significant business impact, VIP customer issue'},\n",
    "                {'label': 'Medium', 'description': 'Feature not working as expected, moderate inconvenience, standard request'},\n",
    "                {'label': 'Low', 'description': 'Minor issue, cosmetic problem, general question, feature request'}\n",
    "            ],\n",
    "            {'task_description': 'Classify support ticket urgency', 'output_mode': 'single'}\n",
    "        ) as urgency_classification,\n",
    "        \n",
    "        -- Classify ticket category\n",
    "        AI_CLASSIFY(\n",
    "            t.TICKET_DESCRIPTION,\n",
    "            [\n",
    "                {'label': 'Technical Issue', 'description': 'Technical problems, bugs, errors, system not working'},\n",
    "                {'label': 'Billing', 'description': 'Billing questions, payment issues, invoice problems, refund requests'},\n",
    "                {'label': 'Feature Request', 'description': 'New feature suggestions, enhancement requests, product improvements'},\n",
    "                {'label': 'Account Management', 'description': 'Account access, password resets, profile changes, account settings'},\n",
    "                {'label': 'General Inquiry', 'description': 'General questions, how-to requests, information seeking'}\n",
    "            ],\n",
    "            {'task_description': 'Categorize support ticket type', 'output_mode': 'single'}\n",
    "        ) as category_classification,\n",
    "        \n",
    "        -- Analyze multi-dimensional sentiment\n",
    "        AI_SENTIMENT(\n",
    "            t.TICKET_DESCRIPTION,\n",
    "            ['brand', 'product', 'customer support']\n",
    "        ) as sentiment_json\n",
    "        \n",
    "    FROM {{table_loc}} t\n",
    ")\n",
    "SELECT \n",
    "    ticket_id as TICKET_ID,\n",
    "    description as ORIGINAL_DESCRIPTION,\n",
    "    submit_date as SUBMIT_DATE,\n",
    "    original_priority as ORIGINAL_PRIORITY,\n",
    "    status as STATUS,\n",
    "    customer_tier as CUSTOMER_TIER,\n",
    "    channel as CHANNEL,\n",
    "    \n",
    "    -- Extract metadata from JSON response\n",
    "    metadata_json:issue_type::string as ISSUE_TYPE,\n",
    "    metadata_json:product_area::string as PRODUCT_AREA,\n",
    "    metadata_json:root_cause::string as ROOT_CAUSE,\n",
    "    metadata_json:customer_impact::string as CUSTOMER_IMPACT,\n",
    "    metadata_json:requires_escalation::boolean as REQUIRES_ESCALATION,\n",
    "    metadata_json:system_outage::boolean as SYSTEM_OUTAGE,\n",
    "    metadata_json:mentions_competitor::boolean as MENTIONS_COMPETITOR,\n",
    "    metadata_json:ticket_summary::string as AI_SUMMARY,\n",
    "    \n",
    "    -- Extract classification results\n",
    "    urgency_classification:labels[0]::string as URGENCY_LEVEL,\n",
    "    category_classification:labels[0]::string as CATEGORY,\n",
    "    \n",
    "    -- Extract sentiment analysis\n",
    "    TRIM(sentiment_json:categories[0]:sentiment::string) as OVERALL_SENTIMENT,\n",
    "    TRIM(sentiment_json:categories[1]:sentiment::string) as BRAND_SENTIMENT,\n",
    "    TRIM(sentiment_json:categories[2]:sentiment::string) as PRODUCT_SENTIMENT,\n",
    "    TRIM(sentiment_json:categories[3]:sentiment::string) as SUPPORT_SENTIMENT,\n",
    "    \n",
    "    -- Derive action flags\n",
    "    CASE \n",
    "        WHEN metadata_json:requires_escalation::boolean = TRUE THEN 'Immediate Escalation Required'\n",
    "        WHEN metadata_json:system_outage::boolean = TRUE THEN 'System Outage - Priority Response'\n",
    "        WHEN metadata_json:mentions_competitor::boolean = TRUE THEN 'Retention Risk - Follow Up'\n",
    "        WHEN TRIM(sentiment_json:categories[0]:sentiment::string) = 'negative' \n",
    "             AND urgency_classification:labels[0]::string = 'Critical' THEN 'Critical Negative - Urgent Action'\n",
    "        ELSE 'Standard Processing'\n",
    "    END as ACTION_FLAG,\n",
    "    \n",
    "    -- Generate next action recommendation\n",
    "    AI_COMPLETE(\n",
    "        'claude-4-sonnet',\n",
    "        'In under 10 words, suggest the next action an agent should take for this support case: ' || description\n",
    "    ) as NEXT_ACTION\n",
    "    \n",
    "FROM ticket_processing;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e630dee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Query the processed metadata to see the AI-extracted insights\n",
    "-- This shows how unstructured ticket descriptions are transformed into structured, actionable data\n",
    "\n",
    "SELECT \n",
    "    TICKET_ID,\n",
    "    ISSUE_TYPE,\n",
    "    PRODUCT_AREA,\n",
    "    CUSTOMER_IMPACT,\n",
    "    URGENCY_LEVEL,\n",
    "    CATEGORY,\n",
    "    OVERALL_SENTIMENT,\n",
    "    ACTION_FLAG,\n",
    "    NEXT_ACTION,\n",
    "    AI_SUMMARY\n",
    "FROM SUPPORT_TICKET_METADATA\n",
    "ORDER BY SUBMIT_DATE DESC\n",
    "LIMIT 20;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524bae0d-f119-4707-932c-b719179b48d8",
   "metadata": {
    "collapsed": false,
    "name": "SEARCH_AND_RETRIEVAL"
   },
   "source": [
    "# AI Powered Case Matching\n",
    "Cortex Search enables highly accurate search - using base in class retrieval models - to power RAG use cases.\n",
    "\n",
    "You can create a search service directly in Snowflake, either via the UI (AI > Studio > Cortex Search) - or via SQL similar to the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907542c7-6ed3-45a4-94f7-5582dc02576c",
   "metadata": {
    "language": "sql",
    "name": "create_search_serv"
   },
   "outputs": [],
   "source": [
    "CREATE CORTEX SEARCH SERVICE SUPPORT_SEARCH IF NOT EXISTS\n",
    "  ON ticket_description\n",
    "  ATTRIBUTES submit_date, ticket_ID\n",
    "  WAREHOUSE = tc_wh\n",
    "  TARGET_LAG = '1 day'\n",
    "  EMBEDDING_MODEL = 'snowflake-arctic-embed-l-v2.0'\n",
    "  AS (\n",
    "    SELECT\n",
    "        ticket_id,\n",
    "        submit_date,\n",
    "        customer_id,\n",
    "        ticket_description\n",
    "    FROM {{table_loc}}\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d198ceb-8e60-49ba-ba46-927ada687e7a",
   "metadata": {
    "language": "sql",
    "name": "test_search_SQL"
   },
   "outputs": [],
   "source": [
    "-- We can test how the Search Service works either via the UI - or with a simple SQL query\n",
    "\n",
    "SELECT PARSE_JSON(\n",
    "  SNOWFLAKE.CORTEX.SEARCH_PREVIEW(\n",
    "      'AI_SOL.SUPPORT.SUPPORT_SEARCH',\n",
    "      '{\n",
    "        \"query\": \"show me a case where the customer is experiencing internet issues\",\n",
    "        \"columns\":[\n",
    "            \"ticket_description\",\n",
    "            \"submit_date\"\n",
    "        ],\n",
    "        \"limit\":1\n",
    "      }'\n",
    "  )\n",
    ")['results'] as results;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b38d32-0ca0-4882-a6de-463c4e740682",
   "metadata": {
    "language": "python",
    "name": "query_search_serv"
   },
   "outputs": [],
   "source": [
    "# Now let's test our search service in a simple RAG style scenario\n",
    "from snowflake.core import Root\n",
    "from snowflake.cortex import complete\n",
    "\n",
    "root = Root(session)\n",
    "\n",
    "search_prompt = \"show me a case where the customer is experiencing internet issues\"\n",
    "\n",
    "transcript_search_service = (root\n",
    "  .databases[\"ai_sol\"]\n",
    "  .schemas[\"support\"]\n",
    "  .cortex_search_services[\"support_search\"]\n",
    ")\n",
    "\n",
    "resp = transcript_search_service.search(\n",
    "  query=search_prompt,\n",
    "  columns=[\"ticket_id\", \"ticket_description\"],\n",
    "  limit=1\n",
    ")\n",
    "\n",
    "\n",
    "model = 'claude-3-7-sonnet'\n",
    "\n",
    "llm_call = complete(model,('Give a one line summary and three short key bullet points about this support case. CASE: '+ resp.to_str()))\n",
    "\n",
    "\n",
    "st.write(llm_call) #LLM response\n",
    "st.write('---')\n",
    "st.write(resp.to_json()) #closest matching response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdbf8d6-831b-4fad-a91e-436d7ad0408b",
   "metadata": {
    "collapsed": false,
    "name": "AI_for_BI"
   },
   "source": [
    "# üìä AI for Business Intelligence\n",
    "\n",
    "## üéØ Purpose\n",
    "Learn how to leverage Snowflake's AI capabilities for advanced business intelligence through semantic analysis.\n",
    "\n",
    "## üîë Key Components\n",
    "\n",
    "- **Analyst Tool**: Enables quantitative analysis through natural language queries\n",
    "- **Data Semantics**: Ensures accuracy and consistency in analysis through defined relationships and metrics\n",
    "- **Semantic Views**: Can be created through:\n",
    "  - UI-based configuration in Snowflake interface\n",
    "  - SQL-based definition (demonstrated in next cell)\n",
    "\n",
    "## üí° Benefits\n",
    "- Natural language querying of your data\n",
    "- Consistent metric definitions across your organization\n",
    "- Enhanced data discoverability and understanding\n",
    "- Improved data governance through semantic layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53df19de-0086-4514-9a41-e654c78d82e4",
   "metadata": {
    "collapsed": false,
    "name": "semantic_view_example"
   },
   "source": [
    "If you'd prefer - head to AI > Studio > Cortex Analyst to use the semantic view generator.\n",
    "\n",
    "![smodel](https://docs.snowflake.com/en/_images/cortex-analyst-semantic-model-overview.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3687be-333e-49e4-bd22-e86d0094bcce",
   "metadata": {
    "language": "sql",
    "name": "create_semantic_view"
   },
   "outputs": [],
   "source": [
    "-- The SQL interface makes integration with other platforms far simpler.\n",
    "-- Now enhanced with AI-extracted metadata for deeper insights\n",
    "CREATE OR REPLACE SEMANTIC VIEW support_analysis \n",
    "\n",
    "TABLES (\n",
    "  tickets AS AI_SOL.SUPPORT.RAW_SUPPORT_TICKETS \n",
    "  PRIMARY KEY (TICKET_ID) \n",
    "  WITH SYNONYMS ('support cases', 'customer tickets') \n",
    "  COMMENT = 'Main table for support ticket data',\n",
    "  \n",
    "  metadata AS AI_SOL.SUPPORT.SUPPORT_TICKET_METADATA\n",
    "  PRIMARY KEY (TICKET_ID)\n",
    "  WITH SYNONYMS ('ticket insights', 'ai analysis', 'extracted data')\n",
    "  COMMENT = 'AI-extracted metadata and insights from support tickets'\n",
    ")\n",
    "\n",
    "-- Define the relationship between tickets and metadata\n",
    "RELATIONSHIPS(\n",
    "  tickets_to_metadata AS tickets (TICKET_ID) REFERENCES metadata (TICKET_ID)\n",
    ")\n",
    "\n",
    "FACTS (\n",
    "  tickets.response_time AS FIRST_RESPONSE_TIME_HOURS,\n",
    "  tickets.resolution_time AS RESOLUTION_TIME_HOURS\n",
    ") \n",
    "\n",
    "DIMENSIONS (\n",
    "  tickets.submit_date AS SUBMIT_DATE COMMENT = 'Date when the ticket was submitted',\n",
    "  tickets.customer_tier AS CUSTOMER_TIER WITH SYNONYMS ('customer level', 'tier') COMMENT = 'Customer tier level',\n",
    "  tickets.priority AS PRIORITY COMMENT = 'Ticket priority level. Can be one of HIGH, MEDIUM, or LOW',\n",
    "  tickets.product_area AS PRODUCT_AREA WITH SYNONYMS ('product category', 'product type') COMMENT = 'Product area related to the ticket',\n",
    "  tickets.status AS STATUS COMMENT = 'Current status of the ticket',\n",
    "  tickets.sentiment AS SENTIMENT COMMENT = 'Sentiment analysis of the ticket',\n",
    "  tickets.classification AS CLASSIFICATION COMMENT = 'Ticket classification category',\n",
    "  tickets.channel AS CHANNEL COMMENT = 'Channel through which ticket was submitted',\n",
    "  \n",
    "  -- AI-extracted metadata dimensions\n",
    "  metadata.issue_type AS ISSUE_TYPE WITH SYNONYMS ('problem type', 'ticket type') COMMENT = 'AI-classified issue type',\n",
    "  metadata.product_area AS AI_PRODUCT_AREA WITH SYNONYMS ('affected product', 'service area') COMMENT = 'AI-identified product area affected',\n",
    "  metadata.root_cause AS ROOT_CAUSE WITH SYNONYMS ('cause', 'source of issue') COMMENT = 'AI-identified root cause',\n",
    "  metadata.customer_impact AS CUSTOMER_IMPACT WITH SYNONYMS ('impact', 'effect on customer') COMMENT = 'Description of customer impact',\n",
    "  metadata.urgency_level AS URGENCY_LEVEL WITH SYNONYMS ('urgency', 'criticality') COMMENT = 'AI-classified urgency level',\n",
    "  metadata.category AS CATEGORY WITH SYNONYMS ('ticket category', 'classification') COMMENT = 'AI-classified ticket category',\n",
    "  metadata.overall_sentiment AS OVERALL_SENTIMENT WITH SYNONYMS ('sentiment', 'customer mood') COMMENT = 'Overall sentiment analysis',\n",
    "  metadata.brand_sentiment AS BRAND_SENTIMENT COMMENT = 'Sentiment towards brand',\n",
    "  metadata.product_sentiment AS PRODUCT_SENTIMENT COMMENT = 'Sentiment towards product',\n",
    "  metadata.support_sentiment AS SUPPORT_SENTIMENT COMMENT = 'Sentiment towards customer support',\n",
    "  metadata.action_flag AS ACTION_FLAG WITH SYNONYMS ('priority flag', 'action required') COMMENT = 'Action flag for special handling',\n",
    "  metadata.requires_escalation AS REQUIRES_ESCALATION COMMENT = 'Whether ticket requires escalation',\n",
    "  metadata.system_outage AS SYSTEM_OUTAGE WITH SYNONYMS ('outage', 'service disruption') COMMENT = 'Whether ticket mentions system outage',\n",
    "  metadata.mentions_competitor AS MENTIONS_COMPETITOR WITH SYNONYMS ('competitor mention', 'churn risk') COMMENT = 'Whether customer mentions competitor'\n",
    ") \n",
    "\n",
    "-- Enhanced metrics with AI insights\n",
    "METRICS (\n",
    "  tickets.ticket_count AS COUNT(tickets.TICKET_ID) COMMENT = 'Total number of support tickets',\n",
    "  tickets.avg_response_time AS AVG(tickets.FIRST_RESPONSE_TIME_HOURS) COMMENT = 'Average first response time in hours',\n",
    "  tickets.avg_resolution_time AS AVG(tickets.RESOLUTION_TIME_HOURS) COMMENT = 'Average resolution time in hours',\n",
    "  tickets.negative_sentiment_rate AS AVG(\n",
    "    CASE\n",
    "      WHEN tickets.SENTIMENT ILIKE '%negative%' THEN 1\n",
    "      ELSE 0\n",
    "    END\n",
    "  ) COMMENT = 'Percentage of tickets with negative sentiment',\n",
    "  \n",
    "  -- AI-powered metrics\n",
    "  metadata.escalation_rate AS AVG(\n",
    "    CASE\n",
    "      WHEN metadata.REQUIRES_ESCALATION = TRUE THEN 1\n",
    "      ELSE 0\n",
    "    END\n",
    "  ) COMMENT = 'Percentage of tickets requiring escalation',\n",
    "  \n",
    "  metadata.outage_tickets AS COUNT(\n",
    "    CASE\n",
    "      WHEN metadata.SYSTEM_OUTAGE = TRUE THEN metadata.TICKET_ID\n",
    "      ELSE NULL\n",
    "    END\n",
    "  ) COMMENT = 'Number of tickets mentioning system outages',\n",
    "  \n",
    "  metadata.churn_risk_tickets AS COUNT(\n",
    "    CASE\n",
    "      WHEN metadata.MENTIONS_COMPETITOR = TRUE THEN metadata.TICKET_ID\n",
    "      ELSE NULL\n",
    "    END\n",
    "  ) COMMENT = 'Number of tickets with churn risk (competitor mentions)',\n",
    "  \n",
    "  metadata.critical_tickets AS COUNT(\n",
    "    CASE\n",
    "      WHEN metadata.URGENCY_LEVEL = 'Critical' THEN metadata.TICKET_ID\n",
    "      ELSE NULL\n",
    "    END\n",
    "  ) COMMENT = 'Number of critical urgency tickets',\n",
    "  \n",
    "  metadata.negative_brand_sentiment_rate AS AVG(\n",
    "    CASE\n",
    "      WHEN metadata.BRAND_SENTIMENT = 'negative' THEN 1\n",
    "      ELSE 0\n",
    "    END\n",
    "  ) COMMENT = 'Percentage of tickets with negative brand sentiment',\n",
    "  \n",
    "  metadata.negative_product_sentiment_rate AS AVG(\n",
    "    CASE\n",
    "      WHEN metadata.PRODUCT_SENTIMENT = 'negative' THEN 1\n",
    "      ELSE 0\n",
    "    END\n",
    "  ) COMMENT = 'Percentage of tickets with negative product sentiment'\n",
    "  \n",
    ") COMMENT = 'Enhanced semantic view for support ticket analysis with AI-extracted insights';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c4dcbf-b0d9-4a4f-bd58-166be7800790",
   "metadata": {
    "language": "sql",
    "name": "query_semantic_view"
   },
   "outputs": [],
   "source": [
    "-- Semantic views can be used by AI features (Analyst & Intelligence)\n",
    "-- or BI tools via SELECT *.. for example\n",
    "-- This example shows enhanced analysis with AI-extracted insights\n",
    "\n",
    "SELECT * FROM SEMANTIC_VIEW(\n",
    "    support_analysis \n",
    "    DIMENSIONS tickets.status, metadata.issue_type, metadata.urgency_level\n",
    "    METRICS tickets.ticket_count, tickets.avg_response_time, metadata.escalation_rate, metadata.outage_tickets\n",
    "  );\n",
    "  \n",
    "-- Example: Analyze churn risk and sentiment by product area\n",
    "SELECT * FROM SEMANTIC_VIEW(\n",
    "    support_analysis\n",
    "    DIMENSIONS metadata.product_area, metadata.overall_sentiment\n",
    "    METRICS tickets.ticket_count, metadata.churn_risk_tickets, metadata.negative_brand_sentiment_rate\n",
    "  )\n",
    "  WHERE metadata.product_area IS NOT NULL\n",
    "  ORDER BY metadata.churn_risk_tickets DESC;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2e3420-4bd4-4d18-acff-704ce069343e",
   "metadata": {
    "collapsed": false,
    "name": "finish"
   },
   "source": [
    "# Choose Your Own Adventure\n",
    "\n",
    "You now have multiple options of where your AI project should live:\n",
    "\n",
    "1. Continue to test and refine the Semantic View via Analyst Studio. Simply head to AI > Studio > Cortex Analyst, you'll be able to 'speak' to your semantic view, test how it performs based on standard questions, and refine it further.\n",
    "\n",
    "2. Integrate with a Streamlit application (or similar). Your semantic view is immediately useable by the Cortex Analyst API. You could opt to add SQL generation into an existing application for data discovery.\n",
    "\n",
    "3. Unleash Agentic Insight. Both the search and semantic services you created can become tools for an AI agent. Let's define one using the Agent UI - you'll be able to use this agent in conjunction with Snowflake Intelligence (PrPr).\n",
    "\n",
    "![Snowflake Intelligence](https://github.com/sfc-gh-tchristian/AI-Accelerators/blob/main/AI%20Accelerators%20:%20Support%20Ticket%20Analysis/snowintel.png?raw=true)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "authorEmail": "tom.christian@snowflake.com",
   "authorId": "320484852755",
   "authorName": "TOMGPT",
   "lastEditTime": 1758274089283,
   "notebookId": "jfhoiw6opuaebmie6j6p",
   "sessionId": "975aeeff-ebf5-46eb-b9e8-9af917aeb19d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
