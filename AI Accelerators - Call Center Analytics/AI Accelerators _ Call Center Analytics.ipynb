{
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "lastEditStatus": {
   "notebookId": "u74hmtaffnas5uqtu22n",
   "authorId": "320484852755",
   "authorName": "TOMGPT",
   "authorEmail": "tom.christian@snowflake.com",
   "sessionId": "abb597a8-6529-4639-965b-82b62f99bfe2",
   "lastEditTime": 1760093362737
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4390b0e8-d59c-44fe-9054-89a8db0b0f84",
   "metadata": {
    "name": "INTRO",
    "collapsed": false
   },
   "source": "# ðŸ“ž AI-Powered Call Center Intelligence Demo w/ Snowflake Cortex\n\n`NOTE!` If you're using the provided sample do / do not have audio. Skip to the `SET_UP` cell.\n\n## ðŸŽ¯ Purpose\nThis notebook demonstrates how contact center teams leverage Snowflake's Cortex AI capabilities to transform raw call transcripts into actionable customer intelligence. Experience conversational AI that protects customer privacy, extracts critical information, triages calls by urgency, and analyzes sentimentâ€”all while maintaining compliance and security.\n\n## ðŸ’¡ Why do this?\n- ðŸ”’ **Privacy Protection**: Automatic PII removal to ensure compliance with data protection regulations\n- ðŸ“Š **Intelligent Extraction**: AI-driven entity extraction to capture key customer information and call details\n- ðŸŽ¯ **Smart Triaging**: Automated call classification to route issues to the right teams\n- ðŸ˜Š **Sentiment Analysis**: Real-time customer satisfaction insights to identify at-risk accounts\n- ðŸ“ˆ **Quality Assurance**: Identify coaching opportunities and best practices\n- âš¡ **Response Acceleration**: Generate contextual responses to reduce handle time\n\n## ðŸ› ï¸ Solution Components\nNote: This demo uses SQL & Python to showcase Snowflake Cortex capabilities for call center intelligence\n\n1. ðŸ”’ **Privacy-First Processing**\n   - Automatic PII detection and redaction using `AI_COMPLETE`\n   - Structured output for compliance tracking\n   - Secure data handling throughout the pipeline\n\n2. ðŸ¤– **AI-Powered Call Analysis**\n   - Entity extraction with `AI_EXTRACT` for customer details, issues, and resolutions\n   - Multi-dimensional call classification with `AI_CLASSIFY`\n   - Customer sentiment scoring with `AI_SENTIMENT`\n   - Agent performance assessment\n\n3. âš™ï¸ **Automated Intelligence Pipeline**\n   - Real-time processing of new call transcripts\n   - Automatic quality scoring and alert generation\n   - Trend detection and pattern recognition\n\n4. ðŸŽ¯ **Interactive Call Center Dashboard**\n   - Natural language queries for call analysis\n   - Agent performance metrics and coaching insights\n   - Customer satisfaction trends and risk indicators\n\n## ðŸŒŸ Common Scenarios\n*\"Show me all calls where customers were dissatisfied with billing issues.\"*\n\n*\"Which agents have the highest customer satisfaction scores this month?\"*\n\n*\"Identify calls that need urgent follow-up based on sentiment and issue type.\"*\n\n*\"Generate a response template for common roaming charge complaints.\"*\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520bf4ac-e01a-40bd-b673-520136854df4",
   "metadata": {
    "name": "imports",
    "language": "python"
   },
   "outputs": [],
   "source": "# Core packages for call center analytics and visualization\nimport streamlit as st\nimport pandas as pd\nimport altair as alt\nimport json\n\n# Snowflake session for AI-powered analytics\nfrom snowflake.snowpark.context import get_active_session\n\nsession = get_active_session()\n"
  },
  {
   "cell_type": "markdown",
   "id": "05c86a3c-eff8-4493-8271-9782f7ee8a83",
   "metadata": {
    "name": "TRANSCRIBE",
    "collapsed": false
   },
   "source": "## Cortex powered Transcription:\nThe first step in our call center intelligence pipeline is converting audio recordings into searchable, analysable text using `AI_TRANSCRIBE`. This powerful function:\n\n- Automatically transcribes audio files into text\n- Identifies different speakers in the conversation\n- Captures timestamps for precise analysis\n- Maintains high accuracy across accents and audio quality\n\nYou can configure the settings to adjust for:\n- **Speaker Labels**: Identifies customer vs agent segments\n- **Timestamp Granularity**: Speaker-level timing for detailed analysis\n- **Audio Support**: Handles common call recording formats\n- **Scalable Processing**: Automatically processes new uploads"
  },
  {
   "cell_type": "code",
   "id": "a97abd67-f3e5-4e81-a47f-612c5e5e9687",
   "metadata": {
    "language": "sql",
    "name": "audio_stage"
   },
   "outputs": [],
   "source": "CREATE SCHEMA IF NOT EXISTS AI_SOL.CALL_CENTERS;\n\nCREATE STAGE IF NOT EXISTS AI_SOL.CALL_CENTERS.audio_files_stage -- if you already have an external file location (eg. S3) with audios, point this there.\n    DIRECTORY = ( ENABLE = true )\n    ENCRYPTION = ( TYPE = 'SNOWFLAKE_SSE' );\n\nLIST @AI_SOL.CALL_CENTERS.audio_files_stage; -- if you haven't already, place your audio files here.",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "428049bc-9bd5-476f-b4cf-f594cb47dac1",
   "metadata": {
    "language": "sql",
    "name": "audio_to_text"
   },
   "outputs": [],
   "source": "CREATE TABLE IF NOT EXISTS AI_SOL.CALL_CENTERS.transcribed_data AS (\nSELECT\nTO_FILE('@AI_SOL.CALL_CENTERS.audio_files_stage', RELATIVE_PATH) AS audio_file,\nAI_TRANSCRIBE (TO_FILE('@AI_SOL.CALL_CENTERS.audio_files_stage', RELATIVE_PATH),\n    {'timestamp_granularity': 'speaker'}) AS raw_transcript -- note: you have the option of word level timestamps, speaker, or none\nFROM DIRECTORY(@AI_SOL.CALL_CENTERS.audio_files_stage));",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d4973b-8b78-4e3e-a01d-4539e16b00da",
   "metadata": {
    "name": "SET_UP",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Call center data configuration\n",
    "transcripts_table = 'AI_SOL.CALL_CENTERS.TRANSCRIBED_DATA'\n",
    "\n",
    "# Display table location for reference\n",
    "st.markdown(f\"\"\"\n",
    "**Call Center Data Sources:**\n",
    "- ðŸ“ž Call Transcripts: `{transcripts_table}`\n",
    "  - AUDIO_FILE: Metadata about the audio recording\n",
    "  - RAW_TRANSCRIPT: Full conversation transcript with speaker labels\n",
    "\"\"\")\n",
    "\n",
    "# Quick data preview\n",
    "st.markdown(\"### ðŸ“Š Data Preview\")\n",
    "preview_df = session.table(transcripts_table).limit(3).to_pandas()\n",
    "st.dataframe(preview_df, use_container_width=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f4290e-6d45-46ec-89a8-931db3069cf8",
   "metadata": {
    "name": "PII_REMOVAL"
   },
   "source": [
    "# ðŸ”’ Privacy-First Processing: PII Removal with AI_COMPLETE\n",
    "\n",
    "Before we can analyze call data, we must ensure customer privacy and regulatory compliance. Using `AI_COMPLETE` with structured outputs, we can intelligently identify and redact Personally Identifiable Information (PII) while maintaining the context needed for analysis.\n",
    "\n",
    "This approach goes beyond simple pattern matchingâ€”it understands context to avoid false positives and ensures comprehensive PII protection.\n",
    "\n",
    "## ðŸŽ¯ What We'll Redact:\n",
    "- **Customer Names**: Full names mentioned in conversations\n",
    "- **Phone Numbers**: Mobile and landline numbers\n",
    "- **Account Numbers**: Customer account identifiers\n",
    "- **Addresses**: Physical locations and postcodes\n",
    "- **Payment Information**: Credit card details, bank information\n",
    "- **Personal Identifiers**: Dates of birth, email addresses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    },
    "name": "ai_complete",
    "language": "sql"
   },
   "outputs": [],
   "source": "-- AI-powered PII removal with structured tracking\n-- This demonstrates intelligent PII detection and redaction while maintaining audit trails for compliance\n\n-- NOTE: the converted audio is semi-structured, you're still able to access and operate on that data.\n\nSELECT \n    AUDIO_FILE,\n    RAW_TRANSCRIPT as original_transcript,\n    AI_COMPLETE(\n        model => 'claude-sonnet-4-5',\n        prompt => 'You are a data privacy expert. Analyze the following call transcript and redact all PII while preserving the conversation context and business value. Replace PII with generic placeholders like [CUSTOMER_NAME], [PHONE_NUMBER], [ACCOUNT_NUMBER], [ADDRESS], [POSTCODE], [EMAIL], [DATE_OF_BIRTH], etc.' ||\n                  '\\n\\nCALL TRANSCRIPT:\\n' || \n                  RAW_TRANSCRIPT || \n                  '\\n\\nProvide the redacted transcript and list all PII types found.',\n        response_format => {\n            'type': 'json',\n            'schema': {\n                'type': 'object',\n                'properties': {\n                    'redacted_transcript': {\n                        'type': 'string',\n                        'description': 'The full transcript with all PII replaced by generic placeholders'\n                    },\n                    'pii_types_found': {\n                        'type': 'array',\n                        'items': {'type': 'string'},\n                        'description': 'List of PII types detected (e.g., customer_name, phone_number, account_number)'\n                    },\n                    'pii_count': {\n                        'type': 'integer',\n                        'description': 'Total number of PII instances redacted'\n                    },\n                    'contains_sensitive_financial': {\n                        'type': 'boolean',\n                        'description': 'Whether the call contained sensitive financial information'\n                    }\n                },\n                'required': ['redacted_transcript', 'pii_types_found', 'pii_count', 'contains_sensitive_financial'],\n                'additionalProperties': false\n            }\n        }\n    ) as pii_analysis\nFROM {{transcripts_table}}\nLIMIT 5;\n",
   "id": "ce110000-1111-2222-3333-ffffff000000"
  },
  {
   "cell_type": "markdown",
   "id": "3de56666-8f2c-489e-99c9-d2e08e2fb8f9",
   "metadata": {
    "name": "ENTITY_EXTRACT"
   },
   "source": [
    "# ðŸ“Š Entity Extraction: Capturing Key Call Information with AI_EXTRACT\n",
    "\n",
    "Now that we've protected customer privacy, let's extract the valuable business intelligence from our calls. Using `AI_EXTRACT`, we can automatically identify and structure key information from unstructured conversation transcripts.\n",
    "\n",
    "This transforms hours of manual call review into instant, structured insights.\n",
    "\n",
    "## ðŸŽ¯ What We'll Extract:\n",
    "- **Agent Information**: Name, department, performance indicators\n",
    "- **Customer Details**: Issue type, account status, contact reason\n",
    "- **Call Outcomes**: Resolution status, follow-up required, actions taken\n",
    "- **Product/Service**: Specific products or services discussed\n",
    "- **Financial Details**: Charges, refunds, pricing discussed (amounts only, no account numbers)\n",
    "- **Call Metadata**: Duration, escalation status, callback scheduled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    },
    "name": "AI_EXTRACT",
    "language": "sql"
   },
   "outputs": [],
   "source": "-- AI-powered entity extraction from call transcripts with Agent QA Focus\n-- This demonstrates intelligent information extraction\n-- to structure unstructured conversation data with emphasis on agent performance\n\nSELECT \n    AUDIO_FILE:RELATIVE_PATH::string as call_id,\n    RAW_TRANSCRIPT:audio_duration::float as call_duration,\n    AI_EXTRACT(\n        text => RAW_TRANSCRIPT:text::string,\n        responseFormat => [\n            ['agent_name', 'What is the name of the customer service agent handling this call?'],\n            ['agent_greeting_quality', 'How would you rate the quality of the agent greeting and opening? (Professional, Adequate, Poor, or Missing)'],\n            ['agent_professionalism', 'Did the agent maintain a professional and courteous tone throughout the entire call? (Excellent, Good, Fair, or Poor)'],\n            ['agent_empathy', 'Did the agent demonstrate empathy and active listening? Provide specific examples or quotes from the transcript.'],\n            ['agent_knowledge', 'Did the agent demonstrate adequate product and service knowledge? Were there any knowledge gaps or hesitation?'],\n            ['agent_problem_solving', 'How effectively did the agent troubleshoot and resolve the issue? Rate as Excellent, Good, Fair, or Poor and explain.'],\n            ['agent_communication_clarity', 'Was the agent communication clear, concise, and easy to understand? Provide examples of good or poor communication.'],\n            ['agent_hold_handling', 'If the customer was placed on hold, did the agent explain why, ask permission, and provide updates? (Yes/No/Not Applicable)'],\n            ['agent_closing_quality', 'Did the agent properly summarize the resolution, confirm customer understanding, and ensure satisfaction before closing? (Yes/No/Partial)'],\n            ['agent_compliance', 'Did the agent follow required compliance steps like identity verification or providing disclosures? (Yes/No/Partial)'],\n            ['customer_issue_type', 'What was the primary reason for the call? (e.g., billing, technical support, account inquiry, complaint, upgrade)'],\n            ['issue_description', 'Provide a brief but comprehensive description of the customer issue or request.'],\n            ['resolution_provided', 'Was the customer issue fully resolved during this call? (True/False)'],\n            ['resolution_details', 'Describe how the issue was resolved or what next steps were provided to the customer.'],\n            ['products_services_mentioned', 'List all products or services discussed during the call (e.g., data plans, devices, roaming, insurance).'],\n            ['financial_amounts', 'List any monetary amounts discussed including charges, refunds, credits, or prices mentioned.'],\n            ['follow_up_required', 'Is follow-up action required after this call? (True/False)'],\n            ['follow_up_details', 'If follow-up is required, what specific actions need to be taken and by when?'],\n            ['customer_satisfaction_indicators', 'What specific phrases, words, or tone from the customer indicated their level of satisfaction or dissatisfaction?'],\n            ['escalation_occurred', 'Was this call escalated to a supervisor or did the customer request escalation? (True/False)'],\n            ['escalation_reason', 'If escalated, what was the specific reason for the escalation?'],\n            ['call_outcome', 'What was the overall outcome of the call? (resolved, pending_followup, escalated, callback_scheduled, unresolved)'],\n            ['qa_score_recommendation', 'Based on the agent overall performance, what QA score (1-10) would you recommend and why?'],\n            ['agent_strengths', 'What specific strengths did this agent demonstrate during the call?'],\n            ['coaching_opportunities', 'What specific coaching opportunities or improvement areas exist for this agent? Be detailed and actionable.']\n        ]\n    ) as extracted_entities\nFROM {{transcripts_table}}\nLIMIT 5;",
   "id": "ce110000-1111-2222-3333-ffffff000001"
  },
  {
   "cell_type": "markdown",
   "id": "63ffe19a-013c-4901-9615-bd2c7c5c4a86",
   "metadata": {
    "name": "CALL_TRIAGE"
   },
   "source": [
    "# ðŸŽ¯ Smart Call Triaging with AI_CLASSIFY\n",
    "\n",
    "Effective call center operations require intelligent routing and prioritization. Using `AI_CLASSIFY`, we can automatically categorize calls by urgency, department, and issue complexity to ensure the right resources handle each customer interaction.\n",
    "\n",
    "This goes beyond keyword matchingâ€”it understands context, tone, and business impact to make intelligent routing decisions.\n",
    "\n",
    "## ðŸŽ¯ Classification Dimensions:\n",
    "- **Urgency Level**: Critical, High, Medium, Low\n",
    "- **Department**: Billing, Technical Support, Sales, Retention, Complaints\n",
    "- **Complexity**: Simple, Moderate, Complex, Escalation Required\n",
    "- **Customer Risk**: At-Risk, Neutral, Satisfied, Promoter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    },
    "name": "AI_CLASSIFY",
    "language": "sql"
   },
   "outputs": [],
   "source": "-- Multi-dimensional call classification\n-- This demonstrates intelligent call routing and prioritization\n\nSELECT \n    AUDIO_FILE:RELATIVE_PATH::string as call_id,\n    RAW_TRANSCRIPT:text::string as transcript_text,\n    -- Classify by urgency level\n    AI_CLASSIFY(\n        RAW_TRANSCRIPT:text::string,\n        [\n            {'label': 'Critical', 'description': 'Service completely down, customer threatening to leave, regulatory compliance issue, or severe customer dissatisfaction'},\n            {'label': 'High', 'description': 'Significant service degradation, billing dispute over large amount, repeated unresolved issue, or customer expressing strong frustration'},\n            {'label': 'Medium', 'description': 'Standard service request, moderate billing question, upgrade inquiry, or general troubleshooting'},\n            {'label': 'Low', 'description': 'Simple information request, minor account update, or routine inquiry with positive customer tone'}\n        ],\n        {\n            'task_description': 'Classify call urgency based on issue severity and customer sentiment',\n            'output_mode': 'single'\n        }\n    ) as urgency_classification,\n    \n    -- Classify by department\n    AI_CLASSIFY(\n        RAW_TRANSCRIPT:text::string,\n        [\n            {'label': 'Billing & Payments', 'description': 'Bill questions, payment issues, charges, refunds, pricing inquiries, or payment method updates'},\n            {'label': 'Technical Support', 'description': 'Device issues, network problems, connectivity, settings, troubleshooting, or technical configuration'},\n            {'label': 'Sales & Upgrades', 'description': 'New services, phone upgrades, plan changes, add-ons, or product information'},\n            {'label': 'Retention & Loyalty', 'description': 'Cancellation requests, competitive offers, loyalty discounts, or contract negotiations'},\n            {'label': 'Customer Complaints', 'description': 'Service complaints, poor experience, escalation requests, or formal complaint filing'},\n            {'label': 'Account Management', 'description': 'Account updates, SIM replacement, address changes, or general account maintenance'}\n        ],\n        {\n            'task_description': 'Route call to appropriate department based on primary issue',\n            'output_mode': 'single'\n        }\n    ) as department_classification,\n    \n    -- Classify by complexity\n    AI_CLASSIFY(\n        RAW_TRANSCRIPT:text::string,\n        [\n            {'label': 'Simple - Self-Service', 'description': 'Could be handled by automated system or basic FAQ, single-step resolution'},\n            {'label': 'Moderate - Standard Agent', 'description': 'Requires agent assistance but follows standard procedures, resolved in single call'},\n            {'label': 'Complex - Senior Agent', 'description': 'Requires specialized knowledge, multiple systems, or policy exceptions'},\n            {'label': 'Escalation Required', 'description': 'Needs supervisor approval, legal review, or senior management involvement'}\n        ],\n        {\n            'task_description': 'Assess call complexity for appropriate resource allocation',\n            'output_mode': 'single'\n        }\n    ) as complexity_classification\n    \nFROM {{transcripts_table}}\nLIMIT 100;\n",
   "id": "ce110000-1111-2222-3333-ffffff000002"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47872f3-fbe3-4963-9046-53c008f4125b",
   "metadata": {
    "name": "Classify_streamlit",
    "language": "python"
   },
   "outputs": [],
   "source": "# Analyze call classifications\nst.markdown(\"### ðŸŽ¯ Call Classification Analysis\")\n\nclass_df = AI_CLASSIFY.to_pandas()\n\n# Parse classification results\ndef extract_label(json_str):\n    try:\n        data = json.loads(json_str)\n        labels = data.get('labels', [])\n        return labels[0] if labels else 'Unknown'\n    except:\n        return 'Unknown'\n\nclass_df['urgency'] = class_df['URGENCY_CLASSIFICATION'].apply(extract_label)\nclass_df['department'] = class_df['DEPARTMENT_CLASSIFICATION'].apply(extract_label)\nclass_df['complexity'] = class_df['COMPLEXITY_CLASSIFICATION'].apply(extract_label)\n\n# Display distribution charts\ncol1, col2, col3 = st.columns(3)\n\nwith col1:\n    st.markdown(\"#### Urgency Distribution\")\n    urgency_chart = alt.Chart(class_df).mark_arc().encode(\n        theta=alt.Theta('count():Q'),\n        color=alt.Color('urgency:N', \n                       scale=alt.Scale(domain=['Critical', 'High', 'Medium', 'Low'],\n                                     range=['#d62728', '#ff7f0e', '#ffbb78', '#98df8a'])),\n        tooltip=['urgency', 'count()']\n    ).properties(height=200)\n    st.altair_chart(urgency_chart, use_container_width=True)\n\nwith col2:\n    st.markdown(\"#### Department Distribution\")\n    dept_chart = alt.Chart(class_df).mark_bar().encode(\n        y=alt.Y('department:N', title='', sort='-x'),\n        x=alt.X('count():Q', title='Calls'),\n        color=alt.Color('department:N', legend=None),\n        tooltip=['department', 'count()']\n    ).properties(height=200)\n    st.altair_chart(dept_chart, use_container_width=True)\n\nwith col3:\n    st.markdown(\"#### Complexity Distribution\")\n    complexity_chart = alt.Chart(class_df).mark_arc().encode(\n        theta=alt.Theta('count():Q'),\n        color=alt.Color('complexity:N', scale=alt.Scale(scheme='blues')),\n        tooltip=['complexity', 'count()']\n    ).properties(height=200)\n    st.altair_chart(complexity_chart, use_container_width=True)\n\n# Priority matrix\nst.markdown(\"### ðŸ“Š Priority Matrix: Urgency vs Complexity\")\npriority_matrix = class_df.groupby(['urgency', 'complexity']).size().reset_index(name='count')\nheatmap = alt.Chart(priority_matrix).mark_rect().encode(\n    x=alt.X('complexity:N', title='Complexity'),\n    y=alt.Y('urgency:N', title='Urgency'),\n    color=alt.Color('count:Q', scale=alt.Scale(scheme='blues'), title='Call Count'),\n    tooltip=['urgency', 'complexity', 'count']\n).properties(height=300)\nst.altair_chart(heatmap, use_container_width=True)\n"
  },
  {
   "cell_type": "markdown",
   "id": "635876e4-06d6-4cf8-aed4-4664658b8f8e",
   "metadata": {
    "name": "SENTIMENT"
   },
   "source": [
    "# ðŸ˜Š Customer Sentiment Analysis with AI_SENTIMENT\n",
    "\n",
    "Understanding customer satisfaction in real-time is critical for retention and service quality. Using `AI_SENTIMENT`, we can analyze the emotional tone of conversations to identify at-risk customers, coaching opportunities, and service excellence.\n",
    "\n",
    "This provides instant feedback on customer experience without waiting for post-call surveys.\n",
    "\n",
    "## ðŸŽ¯ Sentiment Insights:\n",
    "- **Overall Call Sentiment**: Positive, Neutral, Negative scores\n",
    "- **Sentiment Trajectory**: How sentiment changed during the call\n",
    "- **Agent Performance**: Impact of agent responses on customer satisfaction\n",
    "- **Risk Indicators**: Early warning signs of customer churn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    },
    "name": "AI_SENTIMENT",
    "language": "sql"
   },
   "outputs": [],
   "source": "-- Comprehensive sentiment analysis of customer calls\n-- This analyzes both overall sentiment and customer-specific sentiment\n\nWITH call_segments AS (\n    SELECT \n        AUDIO_FILE:RELATIVE_PATH::string as call_id,\n        RAW_TRANSCRIPT:text::string as full_transcript,\n        RAW_TRANSCRIPT:audio_duration::float as call_duration,\n        -- Extract customer segments (SPEAKER_01 is typically the customer)\n        ARRAY_TO_STRING(\n            ARRAY_AGG(\n                CASE \n                    WHEN seg.value:speaker_label = 'SPEAKER_01' \n                    THEN seg.value:text::string \n                END\n            ) WITHIN GROUP (ORDER BY seg.index), \n            ' '\n        ) as customer_text\n    FROM {{transcripts_table}},\n    LATERAL FLATTEN(input => RAW_TRANSCRIPT:segments) seg\n    GROUP BY call_id, full_transcript, call_duration\n)\nSELECT \n    call_id,\n    call_duration,\n    \n    -- Overall call sentiment\n    TRIM(AI_SENTIMENT(full_transcript):categories[0].sentiment) as overall_sentiment,\n    \n    -- Customer-specific sentiment (more indicative of satisfaction)\n    TRIM(AI_SENTIMENT(customer_text):categories[0].sentiment) as customer_sentiment,\n    \n    -- Analyze sentiment of opening (first 20% of call)\n    TRIM(AI_SENTIMENT(SUBSTRING(full_transcript, 1, LENGTH(full_transcript) * 0.2)):categories[0].sentiment) as opening_sentiment,\n    \n    -- Analyze sentiment of closing (last 20% of call)\n    TRIM(AI_SENTIMENT(SUBSTRING(full_transcript, LENGTH(full_transcript) * 0.8)):categories[0].sentiment) as closing_sentiment,\n    \n    full_transcript,\n    customer_text\n    \nFROM call_segments\nLIMIT 100;\n",
   "id": "ce110000-1111-2222-3333-ffffff000003"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c6b714-4be1-4898-a1b3-9d7cf92bf921",
   "metadata": {
    "name": "streamlit_sentiment",
    "language": "python",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Visualize sentiment analysis results\nst.markdown(\"### ðŸ˜Š Customer Sentiment Analysis\")\n\nsentiment_df = AI_SENTIMENT.to_pandas()\n\n# Display key metrics\ncol1, col2, col3, col4 = st.columns(4)\nwith col1:\n    avg_customer_sentiment = (sentiment_df['CUSTOMER_SENTIMENT'] == 'positive').mean()\n    st.metric(\"Positive Sentiment Rate\", f\"{avg_customer_sentiment:.1%}\")\nwith col2:\n    positive_calls = (sentiment_df['CUSTOMER_SENTIMENT'] == 'positive').sum()\n    st.metric(\"Positive Calls\", f\"{positive_calls} ({positive_calls/len(sentiment_df)*100:.0f}%)\")\nwith col3:\n    negative_calls = (sentiment_df['CUSTOMER_SENTIMENT'] == 'negative').sum()\n    st.metric(\"Negative Calls\", f\"{negative_calls} ({negative_calls/len(sentiment_df)*100:.0f}%)\")\nwith col4:\n    improved_calls = ((sentiment_df['CLOSING_SENTIMENT'] == 'positive') & \n                     (sentiment_df['OPENING_SENTIMENT'] == 'negative')).sum()\n    st.metric(\"Improved During Call\", f\"{improved_calls} ({improved_calls/len(sentiment_df)*100:.0f}%)\")\n\n# Sentiment distribution\nst.markdown(\"### ðŸ“Š Sentiment Distribution\")\nsentiment_hist = alt.Chart(sentiment_df).mark_bar().encode(\n    x=alt.X('CUSTOMER_SENTIMENT:N', title='Customer Sentiment'),\n    y=alt.Y('count():Q', title='Number of Calls'),\n    color=alt.Color('CUSTOMER_SENTIMENT:N', \n                   scale=alt.Scale(domain=['positive', 'neutral', 'negative'],\n                                 range=['#2ca02c', '#7f7f7f', '#d62728'])),\n    tooltip=['CUSTOMER_SENTIMENT', 'count()']\n).properties(height=300)\nst.altair_chart(sentiment_hist, use_container_width=True)\n\n# Sentiment trajectory analysis\nst.markdown(\"### ðŸ“ˆ Sentiment Trajectory: Opening vs Closing\")\ntrajectory_data = sentiment_df[['CALL_ID', 'OPENING_SENTIMENT', 'CLOSING_SENTIMENT']].melt(\n    id_vars=['CALL_ID'], \n    var_name='Stage', \n    value_name='Sentiment'\n)\ntrajectory_data['Stage'] = trajectory_data['Stage'].map({\n    'OPENING_SENTIMENT': 'Opening',\n    'CLOSING_SENTIMENT': 'Closing'\n})\n\ntrajectory_chart = alt.Chart(trajectory_data).mark_bar().encode(\n    x=alt.X('Stage:N', title='Call Stage'),\n    y=alt.Y('count():Q', title='Number of Calls'),\n    color=alt.Color('Sentiment:N',\n                   scale=alt.Scale(domain=['positive', 'neutral', 'negative'],\n                                 range=['#2ca02c', '#7f7f7f', '#d62728'])),\n    tooltip=['Stage', 'Sentiment', 'count()']\n).properties(height=300)\nst.altair_chart(trajectory_chart, use_container_width=True)\n\n# At-risk customer identification\nst.markdown(\"### âš ï¸ At-Risk Customers (Negative Sentiment)\")\nat_risk = sentiment_df[sentiment_df['CUSTOMER_SENTIMENT'] == 'negative'].sort_values('CALL_ID')\nif len(at_risk) > 0:\n    st.dataframe(\n        at_risk[['CALL_ID', 'CUSTOMER_SENTIMENT', 'OPENING_SENTIMENT', 'CLOSING_SENTIMENT', 'CALL_DURATION']]\n        .head(10),\n        use_container_width=True\n    )\nelse:\n    st.success(\"No at-risk customers identified in this sample! ðŸŽ‰\")\n"
  },
  {
   "cell_type": "markdown",
   "id": "54bd8336-ceb9-4fc9-b0b5-95e6acd1e734",
   "metadata": {
    "name": "AUTO_ANALYSIS",
    "collapsed": false
   },
   "source": "# ðŸŽ« Automated Case Management System\n\nThe first step in production-ready call center intelligence is automating case creation from calls. Using a **Dynamic Table**, we'll create a continuously updated case management system that:\n\n- Automatically processes new calls as they arrive\n- Extracts key information using AI\n- Assigns urgency levels and routing\n- Tracks sentiment and resolution status\n- Maintains an audit trail for compliance\n\nDynamic Tables in Snowflake automatically refresh based on changes to source data, making this a truly automated pipeline.\n"
  },
  {
   "cell_type": "code",
   "id": "e81b772f-3dce-44ad-81c9-753f95f7d20d",
   "metadata": {
    "language": "sql",
    "name": "dynamic_tables"
   },
   "outputs": [],
   "source": "-- Create automated case management system with Dynamic Table\n-- This processes calls and creates cases automatically as new calls arrive\n-- Target lag controls how fresh the data is (adjust based on your needs)\n\nCREATE OR REPLACE DYNAMIC TABLE CALL_CENTER_CASES\n  TARGET_LAG = '1 day'\n  WAREHOUSE = tc_wh  -- Update to your warehouse\n  AS\nWITH call_processing AS (\n    SELECT \n        AUDIO_FILE:RELATIVE_PATH::string as call_id,\n        RAW_TRANSCRIPT:audio_duration::float as call_duration_seconds,\n        RAW_TRANSCRIPT:text::string as transcript,\n        \n        -- Extract key entities using array format with detailed questions\n        AI_EXTRACT(\n            text => RAW_TRANSCRIPT:text::string,\n            responseFormat => [\n                ['agent_name', 'What is the name of the customer service agent handling this call?'],\n                ['customer_issue_type', 'What was the primary reason for the call? (e.g., billing, technical support, account inquiry, complaint, upgrade)'],\n                ['issue_description', 'Provide a brief but comprehensive description of the customer issue or request.'],\n                ['resolution_provided', 'Was the customer issue fully resolved during this call? (True/False)'],\n                ['resolution_details', 'Describe how the issue was resolved or what next steps were provided to the customer.'],\n                ['products_mentioned', 'List all products or services discussed during the call (e.g., data plans, devices, roaming, insurance).'],\n                ['follow_up_required', 'Is follow-up action required after this call? (True/False)'],\n                ['follow_up_details', 'If follow-up is required, what specific actions need to be taken and by when?'],\n                ['escalation_occurred', 'Was this call escalated to a supervisor or did the customer request escalation? (True/False)']\n            ]\n        ) as entities,\n        \n        -- Classify urgency\n        AI_CLASSIFY(\n            RAW_TRANSCRIPT:text::string,\n            [\n                {'label': 'Critical', 'description': 'Service down, customer threatening to leave, severe dissatisfaction'},\n                {'label': 'High', 'description': 'Significant issue, billing dispute, repeated problem, strong frustration'},\n                {'label': 'Medium', 'description': 'Standard service request, moderate question, general troubleshooting'},\n                {'label': 'Low', 'description': 'Simple inquiry, minor update, routine question'}\n            ],\n            {'task_description': 'Classify urgency level', 'output_mode': 'single'}\n        ) as urgency_class,\n        \n        -- Classify department\n        AI_CLASSIFY(\n            RAW_TRANSCRIPT:text::string,\n            [\n                {'label': 'Billing', 'description': 'Bill questions, payment issues, charges, refunds'},\n                {'label': 'Technical Support', 'description': 'Device issues, network problems, connectivity, troubleshooting'},\n                {'label': 'Sales', 'description': 'New services, upgrades, plan changes, product info'},\n                {'label': 'Retention', 'description': 'Cancellation requests, competitive offers, loyalty'},\n                {'label': 'Complaints', 'description': 'Service complaints, poor experience, escalation requests'}\n            ],\n            {'task_description': 'Route to department', 'output_mode': 'single'}\n        ) as department_class,\n        \n        -- Analyze sentiment\n        TRIM(AI_SENTIMENT(RAW_TRANSCRIPT:text::string):categories[0].sentiment) as customer_sentiment\n        \n    FROM {{transcripts_table}}\n)\nSELECT \n    call_id as CALL_ID,\n    entities:response.agent_name::string as AGENT_NAME,\n    entities:response.customer_issue_type::string as ISSUE_TYPE,\n    entities:response.issue_description::string as ISSUE_DESCRIPTION,\n    entities:response.resolution_provided::boolean as RESOLVED,\n    entities:response.resolution_details::string as RESOLUTION_DETAILS,\n    entities:response.products_mentioned as PRODUCTS_MENTIONED,\n    entities:response.follow_up_required::boolean as FOLLOW_UP_REQUIRED,\n    entities:response.follow_up_details::string as FOLLOW_UP_DETAILS,\n    entities:response.escalation_occurred::boolean as ESCALATED,\n    urgency_class:labels[0]::string as URGENCY_LEVEL,\n    department_class:labels[0]::string as DEPARTMENT,\n    customer_sentiment as SENTIMENT_SCORE,\n    CASE \n        WHEN lower(customer_sentiment) = 'negative' THEN 'At Risk'\n        WHEN lower(customer_sentiment) = 'positive' THEN 'Satisfied'\n        ELSE 'Neutral'\n    END as CUSTOMER_STATUS,\n    ROUND(call_duration_seconds / 60, 2) as DURATION_MINUTES,\n    CASE \n        WHEN entities:response.resolution_provided::boolean = TRUE THEN 'Closed'\n        WHEN entities:response.follow_up_required::boolean = TRUE THEN 'Pending Follow-up'\n        WHEN entities:response.escalation_occurred::boolean = TRUE THEN 'Escalated'\n        ELSE 'Open'\n    END as CASE_STATUS,\n    transcript\nFROM call_processing;\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "54fd5e4b-4829-4606-90f3-ec63df9d4d2c",
   "metadata": {
    "language": "sql",
    "name": "sample_data"
   },
   "outputs": [],
   "source": "SELECT * FROM CALL_CENTER_CASES LIMIT 10;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "21694040-1cb6-4e1e-a497-0caea303c4e3",
   "metadata": {
    "name": "RAG"
   },
   "source": [
    "# ðŸ” Cortex Search for Historical Call Intelligence\n",
    "\n",
    "Now let's enable **semantic search** across all call transcripts. This allows agents to instantly find similar past issues, proven resolutions, and best practices from thousands of historical calls.\n",
    "\n",
    "Unlike keyword search, Cortex Search understands meaning and contextâ€”finding relevant calls even when they use different words to describe the same problem.\n",
    "\n",
    "## ðŸŽ¯ Use Cases:\n",
    "- **\"Show me calls about roaming charges in Europe\"** â†’ Finds all related calls, even if they mention \"international data\" or \"travel fees\"\n",
    "- **\"How did agents handle angry billing complaints?\"** â†’ Returns calls with similar situations and their resolutions\n",
    "- **\"Find technical issues with iPhone 15\"** â†’ Surfaces device-specific problems and solutions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    },
    "name": "CORTEX_SEARCH",
    "language": "sql"
   },
   "outputs": [],
   "source": "-- Create Cortex Search service for semantic search across call transcripts\n-- This indexes call data for fast, intelligent retrieval based on meaning\n\nCREATE OR REPLACE CORTEX SEARCH SERVICE CALL_CENTER_SEARCH\n  ON TRANSCRIPT\n  WAREHOUSE = tc_wh  -- Update to your warehouse\n  TARGET_LAG = '1 day'\n  EMBEDDING_MODEL = 'snowflake-arctic-embed-l-v2.0'\n  AS (\n    SELECT\n        AUDIO_FILE:RELATIVE_PATH::string as call_id,\n        RAW_TRANSCRIPT:text::string as transcript\n    FROM {{transcripts_table}}\n);\n",
   "id": "ce110000-1111-2222-3333-ffffff000005"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078ae893-2409-423f-a2b7-af02119371ea",
   "metadata": {
    "name": "Search_App",
    "language": "python"
   },
   "outputs": [],
   "source": "# Test Cortex Search with sample queries\nst.header(\"ðŸ” Semantic Call Search\")\n\nst.markdown(\"\"\"\nSearch across all historical calls using natural language. The system understands meaning, not just keywords.\n\"\"\")\n\n# Sample search queries to try\nst.markdown(\"**ðŸ’¡ Try these example searches:**\")\ncol1, col2 = st.columns(2)\nwith col1:\n    st.code(\"roaming charges complaints\")\n    st.code(\"billing disputes with angry customers\")\n    st.code(\"network connectivity problems\")\nwith col2:\n    st.code(\"successful retention of canceling customer\")\n    st.code(\"iPhone technical support issues\")\n    st.code(\"payment plan negotiations\")\n\nwith st.form(\"search_form\"):\n    search_query = st.text_input(\n        \"ðŸ”Ž Search historical calls:\",\n        placeholder=\"e.g., 'How were billing disputes resolved successfully?'\"\n    )\n    \n    col1, col2 = st.columns(2)\n    with col1:\n        limit_results = st.slider(\"Number of results:\", 3, 20, 5)\n    with col2:\n        filter_dept = st.selectbox(\n            \"Filter by department (optional):\",\n            [\"All Departments\", \"Billing\", \"Technical Support\", \"Sales\", \"Retention\", \"Complaints\"]\n        )\n    \n    search_submitted = st.form_submit_button(\"Search\")\n\nif search_submitted and search_query:\n    try:\n        from snowflake.core import Root\n        \n        root = Root(session)\n        search_service = (root\n            .databases[\"ai_sol\"]\n            .schemas[\"call_centers\"]\n            .cortex_search_services[\"call_center_search\"]\n        )\n        \n        # Build filter if department selected\n        filter_obj = None\n        if filter_dept != \"All Departments\":\n            filter_obj = {\"@eq\": {\"DEPARTMENT\": filter_dept}}\n        \n        # Perform search\n        if filter_obj:\n            search_results = search_service.search(\n                query=search_query,\n                columns=[\"CALL_ID\", \"TRANSCRIPT\"],\n                limit=limit_results,\n                filter=filter_obj\n            )\n        else:\n            search_results = search_service.search(\n                query=search_query,\n                columns=[\"CALL_ID\", \"TRANSCRIPT\"],\n                limit=limit_results\n            )\n        \n        # Parse results\n        results_json = json.loads(search_results.to_json())\n        \n        if results_json and 'results' in results_json and len(results_json['results']) > 0:\n            st.success(f\"Found {len(results_json['results'])} relevant calls\")\n            \n            # Display each result\n            for i, result in enumerate(results_json['results']):\n                call_id = result.get('CALL_ID', 'N/A')\n                transcript = result.get('TRANSCRIPT', 'No transcript available')\n                \n                with st.expander(f\"ðŸŽ« Call {i+1}: {call_id}\"):\n                    st.markdown(f\"**Call ID:** {call_id}\")\n                    \n                    st.markdown(\"**Transcript:**\")\n                    st.text_area(\n                        label=\"Full Transcript\", \n                        value=transcript, \n                        height=200, \n                        key=f\"transcript_{i}\",\n                        label_visibility=\"collapsed\"\n                    )\n                    \n                    # Generate AI summary for this transcript\n                    with st.spinner(\"Generating AI summary...\"):\n                        summary_prompt = f\"\"\"Provide a concise summary of this call center transcript. Include:\n1. Main issue or reason for the call\n2. Key points discussed\n3. Outcome or resolution\n\nTranscript:\n{transcript[:3000]}\"\"\"  # Limit transcript length for API\n                        \n                        try:\n                            summary_result = session.sql(f\"\"\"\n                                SELECT AI_COMPLETE('claude-sonnet-4-5', $${summary_prompt}$$) as summary\n                            \"\"\").collect()\n                            \n                            if summary_result:\n                                st.markdown(\"**ðŸ¤– AI Summary:**\")\n                                st.info(summary_result[0]['SUMMARY'])\n                            else:\n                                st.warning(\"Could not generate summary\")\n                        except Exception as e:\n                            st.warning(f\"Summary generation unavailable: {str(e)}\")\n        else:\n            st.warning(\"No results found. Try a different search query or check that the search service is ready.\")\n            \n    except Exception as e:\n        st.error(f\"Search service not ready or error occurred: {str(e)}\")\n        st.info(\"Make sure the CALL_CENTER_SEARCH service has been created and has finished indexing.\")\n"
  },
  {
   "cell_type": "markdown",
   "id": "978bc324-0789-4810-bb29-c399229fe2a0",
   "metadata": {
    "name": "SEMANTIC_VIEWS"
   },
   "source": [
    "# ðŸ“Š Semantic View for Natural Language Analytics\n",
    "\n",
    "Semantic Views enable **Cortex Analyst** to understand your call center data and answer business questions in natural language. This empowers managers and executives to explore data conversationally without writing SQL.\n",
    "\n",
    "By defining relationships, metrics, and business context, we create a semantic layer that translates questions like *\"What's the average resolution time for billing issues this month?\"* into accurate SQL queries.\n",
    "\n",
    "## ðŸŽ¯ Key Benefits:\n",
    "- **Self-Service Analytics**: Non-technical users can query data naturally\n",
    "- **Consistent Metrics**: Everyone uses the same definitions\n",
    "- **Data Governance**: Controlled access through semantic layer\n",
    "- **Business Context**: AI understands your domain-specific terminology\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    },
    "name": "sem_view",
    "language": "sql"
   },
   "outputs": [],
   "source": "-- Create semantic view for call center analytics\n-- This enables Cortex Analyst to understand and query your data naturally\n\nCREATE OR REPLACE SEMANTIC VIEW call_center_analytics\nTABLES (\n  cases AS AI_SOL.CALL_CENTERS.CALL_CENTER_CASES \n    PRIMARY KEY (CALL_ID) \n    WITH SYNONYMS ('calls', 'tickets', 'interactions', 'customer contacts')\n    COMMENT = 'Call center cases with AI-extracted intelligence'\n)\nFACTS (\n  cases.call_count AS 1 COMMENT = 'Count of individual calls/cases',\n  cases.duration_minutes AS DURATION_MINUTES COMMENT = 'Call duration in minutes'\n)\nDIMENSIONS (\n  cases.CALL_ID AS CALL_ID \n    WITH SYNONYMS ('ticket id', 'call id', 'case number') \n    COMMENT = 'Unique identifier for each case',\n  \n  cases.agent_name AS AGENT_NAME \n    WITH SYNONYMS ('agent', 'representative', 'support agent', 'rep')\n    COMMENT = 'Name of the agent who handled the call',\n  \n  cases.issue_type AS ISSUE_TYPE \n    WITH SYNONYMS ('problem type', 'issue category', 'call reason')\n    COMMENT = 'Category of customer issue or inquiry',\n  \n  cases.issue_description AS ISSUE_DESCRIPTION \n    WITH SYNONYMS ('problem description', 'issue details')\n    COMMENT = 'Detailed description of the customer issue',\n  \n  cases.department AS DEPARTMENT \n    WITH SYNONYMS ('team', 'group', 'department name')\n    COMMENT = 'Department that handled the call',\n  \n  cases.urgency_level AS URGENCY_LEVEL \n    WITH SYNONYMS ('priority', 'urgency', 'severity')\n    COMMENT = 'Urgency classification: Critical, High, Medium, Low',\n  \n  cases.case_status AS CASE_STATUS \n    WITH SYNONYMS ('status', 'state', 'case state')\n    COMMENT = 'Current status of the case',\n  \n  cases.customer_status AS CUSTOMER_STATUS \n    WITH SYNONYMS ('satisfaction', 'customer state', 'satisfaction level')\n    COMMENT = 'Customer satisfaction status: At Risk, Neutral, Satisfied',\n  \n  cases.resolved AS RESOLVED \n    WITH SYNONYMS ('is resolved', 'resolved flag', 'closed')\n    COMMENT = 'Whether the issue was resolved',\n  \n  cases.follow_up_required AS FOLLOW_UP_REQUIRED \n    WITH SYNONYMS ('needs follow up', 'requires follow up')\n    COMMENT = 'Whether follow-up action is needed',\n  \n  cases.escalated AS ESCALATED \n    WITH SYNONYMS ('is escalated', 'escalation flag')\n    COMMENT = 'Whether the call was escalated'\n)\nMETRICS (\n  cases.total_calls AS COUNT(cases.CALL_ID) \n    COMMENT = 'Total number of calls/cases',\n  \n  cases.resolved_calls AS COUNT(\n    CASE WHEN cases.RESOLVED = TRUE THEN cases.CALL_ID END\n  ) \n    COMMENT = 'Number of resolved calls',\n  \n  cases.unresolved_calls AS COUNT(\n    CASE WHEN cases.RESOLVED = FALSE OR cases.RESOLVED IS NULL THEN cases.CALL_ID END\n  ) \n    COMMENT = 'Number of unresolved calls',\n  \n  cases.resolution_rate AS (\n    COUNT(CASE WHEN cases.RESOLVED = TRUE THEN cases.CALL_ID END) * 100.0 / \n    COUNT(cases.CALL_ID)\n  ) \n    COMMENT = 'Percentage of calls that were resolved',\n  \n  cases.critical_calls AS COUNT(\n    CASE WHEN cases.URGENCY_LEVEL = 'Critical' THEN cases.CALL_ID END\n  ) \n    COMMENT = 'Number of critical priority calls',\n  \n  cases.high_priority_calls AS COUNT(\n    CASE WHEN cases.URGENCY_LEVEL IN ('Critical', 'High') THEN cases.CALL_ID END\n  ) \n    COMMENT = 'Number of high priority calls',\n  \n  cases.at_risk_customers AS COUNT(\n    CASE WHEN cases.CUSTOMER_STATUS = 'At Risk' THEN cases.CALL_ID END\n  ) \n    COMMENT = 'Number of at-risk customer interactions',\n  \n  cases.satisfied_customers AS COUNT(\n    CASE WHEN cases.CUSTOMER_STATUS = 'Satisfied' THEN cases.CALL_ID END\n  ) \n    COMMENT = 'Number of satisfied customer interactions',\n  \n  cases.escalated_calls AS COUNT(\n    CASE WHEN cases.ESCALATED = TRUE THEN cases.CALL_ID END\n  ) \n    COMMENT = 'Number of escalated calls',\n  \n  cases.escalation_rate AS (\n    COUNT(CASE WHEN cases.ESCALATED = TRUE THEN cases.CALL_ID END) * 100.0 / \n    COUNT(cases.CALL_ID)\n  ) \n    COMMENT = 'Percentage of calls that were escalated',\n  \n  cases.avg_call_duration AS AVG(cases.DURATION_MINUTES) \n    COMMENT = 'Average call duration in minutes',\n  \n  cases.total_call_minutes AS SUM(cases.DURATION_MINUTES) \n    COMMENT = 'Total call time in minutes',\n  \n  cases.avg_sentiment AS AVG(cases.SENTIMENT_SCORE) \n    COMMENT = 'Average customer sentiment score (-1 to 1)',\n  \n  cases.calls_needing_followup AS COUNT(\n    CASE WHEN cases.FOLLOW_UP_REQUIRED = TRUE THEN cases.CALL_ID END\n  ) \n    COMMENT = 'Number of calls requiring follow-up'\n)\nCOMMENT = 'Semantic view for conversational call center analytics with Cortex Analyst';\n",
   "id": "ce110000-1111-2222-3333-ffffff000006"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c46dae1-04c3-47c8-ae7e-183964149979",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    },
    "name": "sql_sem_view",
    "language": "sql"
   },
   "outputs": [],
   "source": "-- Test the semantic view with a simple query\n-- Semantic views can be queried directly or used by Cortex Analyst\n-- This example shows resolution rates by department\n\nSELECT * FROM SEMANTIC_VIEW(\n    call_center_analytics\n    DIMENSIONS cases.department, cases.urgency_level\n    METRICS total_calls, escalated_calls, avg_call_duration\n)\nORDER BY total_calls DESC;\n"
  },
  {
   "cell_type": "markdown",
   "id": "8439ad16-ef63-4064-a62d-e0189644cfeb",
   "metadata": {
    "name": "whats_next"
   },
   "source": [
    "# ðŸš€ Next Steps: From Demo to Production\n",
    "\n",
    "Congratulations! You've experienced the power of AI-driven call center intelligence. Here's how to take this from demo to production:\n",
    "\n",
    "## 1. ðŸ”’ **Deploy Privacy Pipeline**\n",
    "Implement the PII removal process as a standard preprocessing step for all call transcripts, ensuring compliance with GDPR, CCPA, and other regulations.\n",
    "\n",
    "## 2. ðŸ“Š **Expand Semantic Views**\n",
    "Head to **AI > Studio > Cortex Analyst** to create semantic views of your call center data, enabling natural language reporting for managers and executives.\n",
    "\n",
    "## 3. ðŸ¤– **Build Agent Assist Tools**\n",
    "Deploy the Streamlit agent assist application to provide real-time intelligence, response suggestions, and quality coaching during live calls.\n",
    "\n",
    "## 4. ðŸ”„ **Automate Case Management**\n",
    "Connect AI extraction and classification to your CRM or ticketing system for automatic case creation, routing, and follow-up tracking.\n",
    "\n",
    "## 5. ðŸ“ˆ **Scale Across Contact Centers**\n",
    "Roll out to your entire organization with:\n",
    "- Team-specific performance dashboards\n",
    "- Real-time quality assurance monitoring\n",
    "- Predictive analytics for staffing and training\n",
    "- Customer experience optimization\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ’¡ **Key Takeaways**\n",
    "\n",
    "âœ… **Privacy-First AI** ensures compliance while extracting maximum value from call data\n",
    "\n",
    "âœ… **Automated Intelligence** transforms hours of manual analysis into instant insights\n",
    "\n",
    "âœ… **Smart Triaging** routes calls to the right resources at the right time\n",
    "\n",
    "âœ… **Sentiment Analysis** provides real-time customer satisfaction monitoring\n",
    "\n",
    "âœ… **Agent Augmentation** empowers teams with AI-powered assistance and coaching\n",
    "\n",
    "---\n",
    "\n",
    "*Ready to revolutionize your call center operations? Start with your own call transcript data and see the transformation firsthand.*\n"
   ]
  }
 ]
}