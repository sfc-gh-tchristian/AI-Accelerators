{
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "lastEditStatus": {
   "notebookId": "5jnklgw5gric43g5mcuf",
   "authorId": "5744486210470",
   "authorName": "CCARRERO",
   "authorEmail": "carlos.carrero@snowflake.com",
   "sessionId": "ae86ce65-fe7e-44e2-b24f-e797549bac84",
   "lastEditTime": 1764255558692
  }
 },
 "nbformat_minor": 2,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000000",
   "metadata": {
    "collapsed": false,
    "name": "INTRO"
   },
   "source": [
    "# ðŸ­ AI-Powered Manufacturing Intelligence Demo w/ Snowflake Cortex\n",
    "\n",
    "## ðŸŽ¯ Purpose\n",
    "This notebook demonstrates how manufacturing teams leverage Snowflake's Cortex AI capabilities to transform traditional JIRA production data into actionable manufacturing intelligence. Experience conversational AI that answers complex operational questions, identifies critical failure patterns, and generates predictive maintenance insights.\n",
    "\n",
    "## ðŸ’¡ Why do this?\n",
    "- ðŸ” **Root Cause Analysis**: AI-driven pattern recognition to identify recurring problems and their sources\n",
    "- âš¡ **Downtime Prevention**: Predictive insights to prevent equipment failures before they occur\n",
    "- ðŸ”§ **Maintenance Optimization**: Intelligent scheduling based on failure patterns and asset health\n",
    "- ðŸ“Š **Compliance Monitoring**: Automated tracking of safety and quality requirements\n",
    "- ðŸ† **Process Excellence**: Identify best practices and replicate high-performing operations\n",
    "- ðŸ“ˆ **Operational Efficiency**: Real-time insights into production line performance and bottlenecks\n",
    "\n",
    "## ðŸ› ï¸ Solution Components\n",
    "Note: This demo uses SQL & Python to showcase Snowflake Cortex capabilities for manufacturing intelligence\n",
    "\n",
    "1. ðŸ“Š **Manufacturing Operations Dashboard**\n",
    "   - Interactive dashboards showing equipment health and incident trends\n",
    "   - Dynamic filtering by production line, shift, and equipment type\n",
    "\n",
    "2. ðŸ¤– **AI-Powered Manufacturing Analysis**\n",
    "   - Equipment summarization using `AI_AGG` across incident history\n",
    "   - Automated root cause detection with `AI_FILTER`\n",
    "   - Multi-dimensional failure analysis with `ENTITY_SENTIMENT`\n",
    "   - Maintenance effectiveness scoring and asset assessment\n",
    "\n",
    "3. âš™ï¸ **Automated Manufacturing Intelligence Pipeline**\n",
    "   - Real-time processing of new production incidents\n",
    "   - Automatic equipment health scoring updates\n",
    "   - Failure pattern tracking and predictive alerts\n",
    "\n",
    "4. ðŸŽ¯ **Conversational Manufacturing Assistant**\n",
    "   - Natural language queries for maintenance planning\n",
    "   - Semantic search across incident history and equipment data\n",
    "   - Contextual recommendations and maintenance actions\n",
    "\n",
    "## ðŸŒŸ Common Scenarios\n",
    "*\"What's causing the most downtime on Production Line A this month?\"*\n",
    "\n",
    "*\"Which equipment showed repeated failures and what was the root cause?\"*\n",
    "\n",
    "*\"Show me all compliance incidents that took longer than 24 hours to resolve.\"*\n",
    "\n",
    "*\"Generate a maintenance plan for Equipment Unit 101 based on recent failure patterns.\"*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000001",
   "metadata": {
    "language": "python",
    "name": "packages"
   },
   "outputs": [],
   "source": [
    "# Core packages for manufacturing analytics and visualization\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "from datetime import datetime, timedelta\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Snowflake session for AI-powered analytics\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000002",
   "metadata": {
    "language": "python",
    "name": "tables"
   },
   "outputs": [],
   "source": [
    "# JIRA data configuration - update these if using your own production data or loaded your data somewhere else!\n",
    "issues_table = 'AI_SOL.JIRA.ISSUES'\n",
    "projects_table = 'AI_SOL.JIRA.PROJECTS'\n",
    "users_table = 'AI_SOL.JIRA.USERS'\n",
    "\n",
    "\n",
    "# Display table locations for reference\n",
    "st.markdown(f\"\"\"\n",
    "**JIRA Data Sources:**\n",
    "- ðŸŽ« JIRA Issues: `{issues_table}`\n",
    "- ðŸ­ Projects: `{projects_table}`  \n",
    "- ðŸ”§ Users: `{users_table}`\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000004",
   "metadata": {
    "name": "EQUIP_INTEL"
   },
   "source": [
    "# ðŸ” AI-Powered Equipment Intelligence\n",
    "\n",
    "Now let's dive into the real power of Cortex AI for manufacturing intelligence. We'll use `AI_AGG` to automatically summarize equipment performance and identify key insights from production incidents.\n",
    "\n",
    "This is where traditional JIRA reporting transforms into intelligent manufacturing assistance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000005",
   "metadata": {
    "language": "sql",
    "name": "AI_AGG",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- AI-powered JIRA issue analysis\n",
    "-- This demonstrates how we can instantly analyze JIRA issues\n",
    "-- by summarizing patterns and extracting key insights\n",
    "\n",
    "SELECT \n",
    "    i.PROJECT_NAME,\n",
    "    i.PROJECT_CODE,\n",
    "    i.ASSIGNEE,\n",
    "    COUNT(i.ID) as total_issues,\n",
    "    COUNT(CASE WHEN i.RESOLVED_TS IS NOT NULL THEN 1 END) as resolved_issues,\n",
    "    AI_AGG(\n",
    "        i.SUMMARY,\n",
    "        'Summarize the project issues and patterns. Highlight recurring problems, common themes, resolution patterns, and current status. Include any patterns related to assignees, priorities, or issue types.'\n",
    "    ) as project_analysis\n",
    "FROM {{issues_table}} i\n",
    "WHERE i.PROJECT_NAME = 'Manufacturing Operations' AND ASSIGNEE='James MÃ¼ller'\n",
    "GROUP BY i.PROJECT_NAME, i.PROJECT_CODE, i.ASSIGNEE\n",
    "LIMIT 30;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a644b6df-108f-4302-a19d-527d5045c95d",
   "metadata": {
    "language": "python",
    "name": "st_write_results"
   },
   "outputs": [],
   "source": [
    "# You can reference results from other cells - handy when you'd like to display the output :)\n",
    "st.write(AI_AGG.to_pandas()[\"PROJECT_ANALYSIS\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000006",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "AGG_app"
   },
   "outputs": [],
   "source": [
    "# JIRA Project Analysis Assistant\n",
    "# although we call it AISQL - you can call the same powerful functions with Python\n",
    "# let's wrap AI_AGG into an application that let's us monitor various projects and people\n",
    "from snowflake.snowpark.functions import col, count_distinct, max, ai_agg\n",
    "\n",
    "st.header(\"ðŸ“Š JIRA Project Analysis Assistant\")\n",
    "\n",
    "# Create DataFrames from tables\n",
    "issues_df = session.table(issues_table)\n",
    "projects_df = session.table(projects_table)\n",
    "users_df = session.table(users_table)\n",
    "\n",
    "# Create interactive project analysis tool\n",
    "with st.form(\"project_analysis\"):\n",
    "    st.markdown(\"### Generate project insights with AI analysis\")\n",
    "    \n",
    "    # Get list of projects for selection \n",
    "    project_list = (issues_df.select('PROJECT_NAME').distinct().sort('PROJECT_NAME').to_pandas()['PROJECT_NAME'].tolist())\n",
    "    \n",
    "    selected_project = st.selectbox(\n",
    "        \"Select Project for Analysis:\",\n",
    "        options=project_list,\n",
    "        index=0 if project_list else None,\n",
    "        key=\"project_select\"\n",
    "    )\n",
    "    \n",
    "    # Get assignees for selected project\n",
    "    if selected_project:\n",
    "        assignee_list = (issues_df\n",
    "            .filter(col('PROJECT_NAME') == selected_project)\n",
    "            .select('ASSIGNEE')\n",
    "            .distinct()\n",
    "            .sort('ASSIGNEE')\n",
    "            .to_pandas()['ASSIGNEE']\n",
    "            .tolist()\n",
    "        )\n",
    "        \n",
    "        selected_assignee = st.selectbox(\n",
    "            \"Select Assignee (Optional):\",\n",
    "            options=[\"All Assignees\"] + assignee_list,\n",
    "            key=\"assignee_select\"\n",
    "        )\n",
    "    \n",
    "    analysis_submitted = st.form_submit_button(\"Generate Project Analysis\")\n",
    "\n",
    "if analysis_submitted and selected_project:\n",
    "    # Build filter conditions\n",
    "    filter_conditions = [col('PROJECT_NAME') == selected_project]\n",
    "    if selected_assignee and selected_assignee != \"All Assignees\":\n",
    "        filter_conditions.append(col('ASSIGNEE') == selected_assignee)\n",
    "    \n",
    "    # Get comprehensive project intelligence\n",
    "    project_analysis = (issues_df\n",
    "        .filter(*filter_conditions)\n",
    "        .group_by(col('PROJECT_NAME'), col('PROJECT_CODE'))\n",
    "        .agg(\n",
    "            count_distinct('ID').alias('TOTAL_ISSUES'),\n",
    "            count_distinct(col('ASSIGNEE')).alias('UNIQUE_ASSIGNEES'),\n",
    "            max('CREATED').alias('LAST_ISSUE_DATE'),\n",
    "            ai_agg(\n",
    "                col('SUMMARY'),\n",
    "                'Create a comprehensive project analysis. Include: 1) Common issue themes and patterns 2) Project health assessment 3) Team workload analysis 4) Priority distribution 5) Recommendations for improvement 6) Key areas of focus. Format as project brief.'\n",
    "            ).alias('PROJECT_ANALYSIS')\n",
    "        )\n",
    "        .collect()\n",
    "    )\n",
    "    \n",
    "    if project_analysis:\n",
    "        analysis = project_analysis[0]\n",
    "        \n",
    "        st.success(f\"Project Analysis Generated for {selected_project}\" + \n",
    "                  (f\" - {selected_assignee}\" if selected_assignee != \"All Assignees\" else \"\"))\n",
    "        \n",
    "        # Display key metrics\n",
    "        col1, col2, col3, col4 = st.columns(4)\n",
    "        with col1:\n",
    "            st.metric(\"Project Code\", analysis['PROJECT_CODE'])\n",
    "        with col2:\n",
    "            st.metric(\"Total Issues\", analysis['TOTAL_ISSUES'])\n",
    "        with col3:\n",
    "            st.metric(\"Team Members\", analysis['UNIQUE_ASSIGNEES'])\n",
    "        with col4:\n",
    "            last_issue = analysis['LAST_ISSUE_DATE']\n",
    "            if last_issue:\n",
    "                st.metric(\"Last Issue\", last_issue.strftime('%Y-%m-%d'))\n",
    "            else:\n",
    "                st.metric(\"Last Issue\", \"N/A\")\n",
    "        \n",
    "        # Display AI-generated analysis\n",
    "        st.markdown(\"### ðŸ“‹ AI-Generated Project Analysis\")\n",
    "        st.markdown(analysis['PROJECT_ANALYSIS'])\n",
    "        \n",
    "        # Get recent issues for this project\n",
    "        recent_issues = (issues_df\n",
    "            .filter(*filter_conditions)\n",
    "            .select(\n",
    "                col('KEY'),\n",
    "                col('SUMMARY'),\n",
    "                col('PRIORITY'),\n",
    "                col('STATUS'),\n",
    "                col('ASSIGNEE'),\n",
    "                col('CREATED')\n",
    "            )\n",
    "            .order_by(col('CREATED').desc())\n",
    "            .limit(10)\n",
    "            .to_pandas()\n",
    "        )\n",
    "        \n",
    "        if not recent_issues.empty:\n",
    "            st.markdown(\"### ðŸŽ« Recent Issues\")\n",
    "            st.dataframe(recent_issues, use_container_width=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000007",
   "metadata": {
    "collapsed": false,
    "name": "RCA_ANALYSIS"
   },
   "source": [
    "# ðŸ” Root Cause Analysis with AI_CLASSIFY\n",
    "\n",
    "One of the key challenges in manufacturing is identifying root causes scattered across incident reports. `AI_CLASSIFY` allows us to intelligently identify recurring problems and their sources, even when root causes aren't explicitly documented.\n",
    "\n",
    "This goes beyond simple keyword matching - it understands context and patterns in failure descriptions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000008",
   "metadata": {
    "codeCollapsed": false,
    "language": "sql",
    "name": "AI_CLASSIFY",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Intelligent issue classification across all JIRA issues\n",
    "-- This finds patterns and classifies issues by type and urgency\n",
    "\n",
    "SELECT \n",
    "    i.KEY,\n",
    "    i.SUMMARY,\n",
    "    AI_CLASSIFY(\n",
    "        i.SUMMARY,\n",
    "        [\n",
    "            {'label': 'Bearing System Failure', 'description': 'bearing overheating, defective bearings, or bearing-induced alignment drift'},\n",
    "            {'label': 'Electrical Component Failure', 'description': 'sensor failures, electrical faults in valves or sensors, or electrical system malfunctions'},\n",
    "            {'label': 'Hydraulic System Leak', 'description': 'leaks in valves, nozzles, seals, or other hydraulic components'},\n",
    "            {'label': 'Sensor Calibration Issue', 'description': 'sensor misread failures, accuracy problems, or calibration drift'},\n",
    "            {'label': 'Mechanical Alignment Problem', 'description': 'alignment drift in nozzles, bearings, sensors, or other mechanical components'},\n",
    "            {'label': 'Thermal Management Failure', 'description': 'overheating of bearings, valves, or other components due to thermal issues'},\n",
    "            {'label': 'Regulatory Compliance Violation', 'description': 'compliance deviations, regulatory reporting issues, or procedural violations'},\n",
    "            {'label': 'Recurring Incident Escalation', 'description': 'repeated failures, unresolved root causes, or escalated production disruptions'}\n",
    "        ],\n",
    "        {\n",
    "            'task_description': 'Classify manufacturing issues by detailed category for operational analysis',\n",
    "            'output_mode': 'single' -- this can be 'multi' if appropriate!\n",
    "        }\n",
    "    ) as issue_category,\n",
    "    i.STATUS\n",
    "FROM {{issues_table}} i\n",
    "ORDER BY i.CREATED DESC;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d861c4f-4024-4181-9a28-87968a752eb9",
   "metadata": {
    "language": "python",
    "name": "cat_classify"
   },
   "outputs": [],
   "source": [
    "# Get data from cell9 and process for visualization\n",
    "df = AI_CLASSIFY.to_pandas()\n",
    "\n",
    "# Extract labels from JSON strings for both columns\n",
    "df['issue_category'] = df['ISSUE_CATEGORY'].str.extract(r'\"labels\":\\s*\\[\\s*\"([^\"]+)\"\\s*\\]')\n",
    "\n",
    "# Display summary metrics\n",
    "st.markdown(\"### Summary Statistics\")\n",
    "\n",
    "most_common_category = df['issue_category'].mode()[0]\n",
    "category_count = df['issue_category'].value_counts().iloc[0]\n",
    "st.metric(\"Most Common Issue Category\", \n",
    "          most_common_category,\n",
    "          f\"{category_count} occurrences\")\n",
    "\n",
    "    \n",
    "# Create category chart\n",
    "category_chart = alt.Chart(df).mark_bar().encode(\n",
    "    x=alt.X('count():Q', title='Count'),\n",
    "    y=alt.Y('issue_category:N', title='Issue Category', sort='-x'),\n",
    "    color=alt.Color('issue_category:N', legend=None, scale=alt.Scale(scheme='blues')),\n",
    "    tooltip=['issue_category', 'count()']\n",
    ").properties(height=300)\n",
    "\n",
    "st.altair_chart(category_chart, use_container_width=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000009",
   "metadata": {
    "collapsed": false,
    "name": "ME_ANALYSIS"
   },
   "source": [
    "# âš¡ Maintenance Effectiveness Analysis with AI Intelligence\n",
    "\n",
    "Maintenance effectiveness is critical for manufacturing operations. Here we use AI to automatically analyze maintenance patterns, resolution times, and repeat failures to assess the health of our maintenance processes.\n",
    "\n",
    "This transforms subjective maintenance assessment into data-driven insights for continuous improvement.\n",
    "\n",
    "In this case using `AI_COMPLETE`, which allows us to run a custom prompt with our model of choice, we can define a strict schema for the LLM to follow. This is perfect for engineering tasks, where structure ensures consistency and pipeline reliability. [See more](https://docs.snowflake.com/en/user-guide/snowflake-cortex/complete-structured-outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000010",
   "metadata": {
    "language": "sql",
    "name": "Structured_outputs",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- With structured outputs, we can extract multiple entities in one request.\n",
    "-- This reduces multiple round hops to the same model for information.\n",
    "-- For accuracy, make the requests related by topic where possible\n",
    "\n",
    "-- Looking to run this on change data periodically? \n",
    "-- Using a dynamic table means we can define the structure\n",
    "-- and Snowflake will manage the pipeline!\n",
    "\n",
    "-- CREATE DYNAMIC TABLE LLM_INSIGHTS\n",
    "--  TARGET_LAG = '60 minute'\n",
    "--  WAREHOUSE = tc_wh --change to your own\n",
    "--  AS\n",
    "\n",
    "SELECT\n",
    "  i.PROJECT_NAME,\n",
    "  i.ASSIGNEE,\n",
    "  i.CREATOR,\n",
    "  AI_COMPLETE(\n",
    "    model => 'claude-sonnet-4-5',\n",
    "    prompt => 'You are an expert in project management and issue analysis. Given the following JIRA issue data, analyze the project patterns and provide structured insights. Only extract information found in the issue summaries. Be precise and factual in your analysis.' || \n",
    "              '\\n\\nJIRA ISSUE DATA:\\n' || \n",
    "              SUMMARY || \n",
    "              '\\nEND OF ISSUE DATA\\n\\n',\n",
    "    response_format => {\n",
    "      'type': 'json',\n",
    "      'schema': {\n",
    "        'type': 'object',\n",
    "        'properties': {\n",
    "          'PROJECT_ANALYSIS': {\n",
    "            'type': 'object',\n",
    "            'properties': {\n",
    "              'part_component': {\n",
    "                'type': 'string',\n",
    "                'description': 'The name of the part that failed'\n",
    "              },\n",
    "              'shows_good_progress': {\n",
    "                'type': 'boolean', \n",
    "                'description': 'TRUE if issues are being resolved in reasonable time with good outcomes'\n",
    "              },\n",
    "              'resolved': {\n",
    "                'type': 'boolean',\n",
    "                'description': 'TRUE if the issue appears to be resolved based on the comments'\n",
    "              },\n",
    "              'high_priority': {\n",
    "                'type': 'boolean',\n",
    "                'description': 'TRUE if issues indicate a high degree of critical importance'\n",
    "              },\n",
    "              'has_good_documentation': {\n",
    "                'type': 'boolean',\n",
    "                'description': 'TRUE if issue summaries are detailed and well-documented'\n",
    "              },\n",
    "              'project_summary': {\n",
    "                'type': 'string',\n",
    "                'description': 'Brief summary of overall project health and key patterns observed'\n",
    "              }\n",
    "            },\n",
    "            'required': ['part_component', 'shows_good_progress', 'resolved', 'high_priority', 'has_good_documentation', 'project_summary'],\n",
    "            'additionalProperties': false\n",
    "          }\n",
    "        },\n",
    "        'required': ['PROJECT_ANALYSIS'],\n",
    "        'additionalProperties': false\n",
    "      }\n",
    "    }\n",
    "  ) AS project_analysis_json\n",
    "FROM\n",
    "  {{issues_table}} AS i\n",
    "WHERE\n",
    "  i.CREATED >= DATEADD(month, -6, CURRENT_DATE())\n",
    "LIMIT 10;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000011",
   "metadata": {
    "language": "sql",
    "name": "JSON_extract",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- By expanding on these results, we're turning unstructured data into structured data! \n",
    "-- This could be particularly useful for quantafiable analysis for Cortex Agents / Snowflake Intelligence\n",
    "-- Now you're able to build a reliable pipeline that goes:\n",
    "-- raw data > AI transform > JSON extract\n",
    "\n",
    "SELECT \n",
    "  PROJECT_NAME,\n",
    "  ASSIGNEE,\n",
    "  project_analysis_json:PROJECT_ANALYSIS.part_component::string as part_component,\n",
    "  project_analysis_json:PROJECT_ANALYSIS.has_good_documentation::boolean as has_good_documentation,\n",
    "  project_analysis_json:PROJECT_ANALYSIS.resolved::boolean as resolved,\n",
    "  project_analysis_json:PROJECT_ANALYSIS.high_priority::boolean as high_priority,\n",
    "  project_analysis_json:PROJECT_ANALYSIS.shows_good_progress::boolean as shows_good_progress,\n",
    "  project_analysis_json:PROJECT_ANALYSIS.project_summary::string as project_summary\n",
    "FROM {{Structured_outputs}};"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000012",
   "metadata": {
    "name": "Generate_Recommendations"
   },
   "source": [
    "# ðŸ“‹ AI-Generated Maintenance Recommendations\n",
    "\n",
    "One of the most valuable applications is generating actionable maintenance recommendations based on incident patterns and equipment history. Using the failure analysis and maintenance data, we can generate specific, contextual recommendations for maintenance teams.\n",
    "\n",
    "This demonstrates how AI can augment human expertise while providing consistent, data-driven guidance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "cell1"
   },
   "source": [
    "# ðŸ”„ Automated Issue Processing Pipeline\n",
    "\n",
    "Now we'll create an automated pipeline using Dynamic Tables to process JIRA issues and extract key metadata. This pipeline continuously processes new issues as they arrive, extracting structured information using AI.\n",
    "\n",
    "This approach mirrors modern data engineering practices where AI transforms unstructured data into structured, queryable formats.\n"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000003"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell2",
    "language": "sql"
   },
   "outputs": [],
   "source": [
    "-- Create automated issue processing pipeline with Dynamic Table\n",
    "-- This processes JIRA issues and extracts key metadata automatically as new issues arrive\n",
    "-- Target lag controls how fresh the data is (adjust based on your needs)\n",
    "\n",
    "CREATE OR REPLACE DYNAMIC TABLE JIRA_ISSUE_METADATA\n",
    "  TARGET_LAG = '1 day'\n",
    "  WAREHOUSE = tc_wh  -- Update to your warehouse\n",
    "  AS\n",
    "WITH issue_processing AS (\n",
    "    SELECT \n",
    "        i.KEY as issue_key,\n",
    "        i.SUMMARY as summary,\n",
    "        i.CREATED as created_date,\n",
    "        i.PRIORITY as priority,\n",
    "        i.STATUS as status,\n",
    "        i.PROJECT_NAME as project_name,\n",
    "        i.ASSIGNEE as assignee,\n",
    "        \n",
    "        -- Extract manufacturing metadata using AI_COMPLETE with structured output\n",
    "        AI_COMPLETE(\n",
    "            model => 'claude-4-sonnet',\n",
    "            prompt => 'You are an expert in manufacturing operations and issue analysis. Analyze this JIRA issue and extract key manufacturing metadata. Only extract information explicitly mentioned in the summary.' ||\n",
    "                      '\\n\\nJIRA ISSUE:\\n' || \n",
    "                      'Key: ' || i.KEY || '\\n' ||\n",
    "                      'Summary: ' || i.SUMMARY || '\\n' ||\n",
    "                      'Priority: ' || i.PRIORITY || '\\n' ||\n",
    "                      'Project: ' || i.PROJECT_NAME || '\\n' ||\n",
    "                      '\\nEND OF ISSUE DATA\\n\\n',\n",
    "            response_format => {\n",
    "                'type': 'json',\n",
    "                'schema': {\n",
    "                    'type': 'object',\n",
    "                    'properties': {\n",
    "                        'equipment_name': {\n",
    "                            'type': 'string',\n",
    "                            'description': 'The specific equipment or asset mentioned (e.g., Press-12, Robot-Arm-7)'\n",
    "                        },\n",
    "                        'failure_type': {\n",
    "                            'type': 'string',\n",
    "                            'description': 'The type of failure or issue (e.g., Hydraulic Leak, Bearing Failure, Electrical Fault)'\n",
    "                        },\n",
    "                        'component_affected': {\n",
    "                            'type': 'string',\n",
    "                            'description': 'The specific component or part that failed (e.g., Valve-X102, Bearing-6204)'\n",
    "                        },\n",
    "                        'production_line': {\n",
    "                            'type': 'string',\n",
    "                            'description': 'The production line affected (e.g., LINE_1, LINE_2)'\n",
    "                        },\n",
    "                        'plant_location': {\n",
    "                            'type': 'string',\n",
    "                            'description': 'The plant or facility location mentioned (e.g., Plant A, Plant B)'\n",
    "                        },\n",
    "                        'downtime_minutes': {\n",
    "                            'type': 'integer',\n",
    "                            'description': 'Estimated downtime in minutes if mentioned'\n",
    "                        },\n",
    "                        'requires_parts': {\n",
    "                            'type': 'boolean',\n",
    "                            'description': 'TRUE if the issue indicates parts are needed for resolution'\n",
    "                        },\n",
    "                        'safety_concern': {\n",
    "                            'type': 'boolean',\n",
    "                            'description': 'TRUE if there are safety or compliance implications mentioned'\n",
    "                        },\n",
    "                        'issue_summary': {\n",
    "                            'type': 'string',\n",
    "                            'description': 'Brief 1-sentence summary of the core issue and impact'\n",
    "                        }\n",
    "                    },\n",
    "                    'required': ['equipment_name', 'failure_type', 'component_affected', 'issue_summary'],\n",
    "                    'additionalProperties': false\n",
    "                }\n",
    "            }\n",
    "        ) as metadata_json,\n",
    "        \n",
    "        -- Classify urgency level\n",
    "        AI_CLASSIFY(\n",
    "            i.SUMMARY,\n",
    "            [\n",
    "                {'label': 'Critical', 'description': 'Production stopped, safety hazard, major equipment failure, immediate action required'},\n",
    "                {'label': 'High', 'description': 'Significant production impact, equipment malfunction, urgent repair needed'},\n",
    "                {'label': 'Medium', 'description': 'Moderate issue, scheduled maintenance, standard troubleshooting'},\n",
    "                {'label': 'Low', 'description': 'Minor issue, routine maintenance, informational'}\n",
    "            ],\n",
    "            {'task_description': 'Classify manufacturing issue urgency', 'output_mode': 'single'}\n",
    "        ) as urgency_classification,\n",
    "        \n",
    "        -- Classify department routing\n",
    "        AI_CLASSIFY(\n",
    "            i.SUMMARY,\n",
    "            [\n",
    "                {'label': 'Maintenance', 'description': 'Equipment repair, mechanical issues, preventive maintenance'},\n",
    "                {'label': 'Electrical', 'description': 'Electrical faults, sensor issues, control systems'},\n",
    "                {'label': 'Quality', 'description': 'Quality control, compliance, inspection issues'},\n",
    "                {'label': 'Operations', 'description': 'Production efficiency, process optimization, line management'},\n",
    "                {'label': 'Safety', 'description': 'Safety incidents, regulatory compliance, hazard reporting'}\n",
    "            ],\n",
    "            {'task_description': 'Route to appropriate department', 'output_mode': 'single'}\n",
    "        ) as department_routing,\n",
    "        \n",
    "        -- Analyze sentiment/tone\n",
    "        TRIM(AI_SENTIMENT(i.SUMMARY):categories[0].sentiment) as issue_sentiment\n",
    "        \n",
    "    FROM {{issues_table}} i\n",
    ")\n",
    "SELECT \n",
    "    issue_key as ISSUE_KEY,\n",
    "    summary as ORIGINAL_SUMMARY,\n",
    "    created_date as CREATED_DATE,\n",
    "    priority as ORIGINAL_PRIORITY,\n",
    "    status as STATUS,\n",
    "    project_name as PROJECT_NAME,\n",
    "    assignee as ASSIGNEE,\n",
    "    \n",
    "    -- Extract metadata from JSON response\n",
    "    metadata_json:equipment_name::string as EQUIPMENT_NAME,\n",
    "    metadata_json:failure_type::string as FAILURE_TYPE,\n",
    "    metadata_json:component_affected::string as COMPONENT_AFFECTED,\n",
    "    metadata_json:production_line::string as PRODUCTION_LINE,\n",
    "    metadata_json:plant_location::string as PLANT_LOCATION,\n",
    "    metadata_json:downtime_minutes::integer as DOWNTIME_MINUTES,\n",
    "    metadata_json:requires_parts::boolean as REQUIRES_PARTS,\n",
    "    metadata_json:safety_concern::boolean as SAFETY_CONCERN,\n",
    "    metadata_json:issue_summary::string as AI_SUMMARY,\n",
    "    \n",
    "    -- Extract classification results\n",
    "    urgency_classification:labels[0]::string as URGENCY_LEVEL,\n",
    "    department_routing:labels[0]::string as DEPARTMENT,\n",
    "    issue_sentiment as SENTIMENT,\n",
    "    \n",
    "    -- Derive additional insights\n",
    "    CASE \n",
    "        WHEN lower(issue_sentiment) = 'negative' AND urgency_classification:labels[0]::string = 'Critical' THEN 'Immediate Action Required'\n",
    "        WHEN metadata_json:safety_concern::boolean = TRUE THEN 'Safety Review Required'\n",
    "        WHEN metadata_json:requires_parts::boolean = TRUE THEN 'Parts Procurement Needed'\n",
    "        ELSE 'Standard Processing'\n",
    "    END as ACTION_FLAG\n",
    "    \n",
    "FROM issue_processing;\n"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000013"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell3",
    "language": "sql"
   },
   "outputs": [],
   "source": [
    "-- Query the processed metadata to see the AI-extracted insights\n",
    "-- This shows how unstructured JIRA summaries are transformed into structured, queryable data\n",
    "\n",
    "SELECT \n",
    "    ISSUE_KEY,\n",
    "    EQUIPMENT_NAME,\n",
    "    FAILURE_TYPE,\n",
    "    COMPONENT_AFFECTED,\n",
    "    PRODUCTION_LINE,\n",
    "    PLANT_LOCATION,\n",
    "    DOWNTIME_MINUTES,\n",
    "    URGENCY_LEVEL,\n",
    "    DEPARTMENT,\n",
    "    ACTION_FLAG,\n",
    "    AI_SUMMARY\n",
    "FROM JIRA_ISSUE_METADATA\n",
    "ORDER BY CREATED_DATE DESC\n",
    "LIMIT 20;\n"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000014"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000015",
   "metadata": {
    "language": "python",
    "name": "issue_management_app"
   },
   "outputs": [],
   "source": [
    "# JIRA Issue Recommendations Generator\n",
    "st.header(\"ðŸ“‹ AI-Powered Issue Management Recommendations\")\n",
    "\n",
    "with st.form(\"recommendations_form\"):\n",
    "    st.markdown(\"### Generate project recommendations based on issue patterns\")\n",
    "    \n",
    "    # Get projects with recent issues\n",
    "    recent_projects = session.sql(f\"\"\"\n",
    "        SELECT DISTINCT \n",
    "            i.PROJECT_NAME,\n",
    "            COUNT(i.ID) as issue_count,\n",
    "            MAX(i.CREATED) as last_issue\n",
    "        FROM {issues_table} i\n",
    "        WHERE i.CREATED >= DATEADD(month, -3, CURRENT_DATE())\n",
    "        GROUP BY i.PROJECT_NAME\n",
    "        ORDER BY issue_count DESC, last_issue DESC\n",
    "        LIMIT 20\n",
    "    \"\"\").to_pandas()\n",
    "\n",
    "    col1, col2, col3 = st.columns(3)    \n",
    "    \n",
    "    selected_project_rec = col1.selectbox(\n",
    "        \"Select Project for Recommendations:\",\n",
    "        options=recent_projects['PROJECT_NAME'].tolist() if not recent_projects.empty else []\n",
    "    )\n",
    "    \n",
    "    recommendation_type = col2.selectbox(\n",
    "        \"Recommendation Focus:\",\n",
    "        [\"Process Improvement\", \"Team Efficiency\", \"Issue Prevention\", \"Quality Enhancement\", \"Workflow Optimization\"]\n",
    "    )\n",
    "    \n",
    "    urgency = col3.selectbox(\n",
    "        \"Priority Level:\",\n",
    "        [\"High Priority\", \"Medium Priority\", \"Low Priority\", \"Routine\"]\n",
    "    )\n",
    "    \n",
    "    generate_recommendations = st.form_submit_button(\"Generate Recommendations\")\n",
    "\n",
    "if generate_recommendations and selected_project_rec:\n",
    "    # Get issue patterns and context for the selected project\n",
    "    recommendations_context = session.sql(f\"\"\"\n",
    "        WITH recent_issues AS (\n",
    "            SELECT \n",
    "                i.SUMMARY,\n",
    "                i.CREATED,\n",
    "                i.PRIORITY,\n",
    "                i.STATUS,\n",
    "                i.ASSIGNEE\n",
    "            FROM {issues_table} i\n",
    "            WHERE i.PROJECT_NAME = '{selected_project_rec}'\n",
    "            ORDER BY i.CREATED DESC\n",
    "            LIMIT 10\n",
    "        ),\n",
    "        project_context AS (\n",
    "            SELECT \n",
    "                i.PROJECT_NAME,\n",
    "                i.PROJECT_CODE,\n",
    "                COUNT(i.ID) as total_issues,\n",
    "                COUNT(CASE WHEN i.STATUS IN ('Open', 'In Progress', 'To Do') THEN 1 END) as open_issues\n",
    "            FROM {issues_table} i\n",
    "            WHERE i.PROJECT_NAME = '{selected_project_rec}'\n",
    "            GROUP BY i.PROJECT_NAME, i.PROJECT_CODE\n",
    "            LIMIT 1\n",
    "        )\n",
    "        SELECT \n",
    "            pc.PROJECT_NAME,\n",
    "            pc.PROJECT_CODE,\n",
    "            pc.total_issues,\n",
    "            pc.open_issues,\n",
    "            AI_COMPLETE(\n",
    "                'claude-4-sonnet',\n",
    "                CONCAT(\n",
    "                    'Generate {recommendation_type} recommendations for project ', pc.PROJECT_NAME, ' (', pc.PROJECT_CODE, '). ',\n",
    "                    'Priority level: {urgency}. Project has ', pc.total_issues, ' total issues with ', pc.open_issues, ' currently open. ',\n",
    "                    'Based on these recent issues: ',\n",
    "                    (SELECT LISTAGG(CONCAT(PRIORITY, ' - ', SUMMARY, ' (Assignee: ', ASSIGNEE, ', Status: ', STATUS, ')'), '; ') FROM recent_issues),\n",
    "                    '. Provide specific, actionable recommendations including: 1) Process improvements 2) Team efficiency measures 3) Issue prevention strategies 4) Quality enhancements 5) Timeline and implementation steps. ',\n",
    "                    'Format as a brief structured project improvement plan with clear priorities and actions. Return in markdown format. /n PROJECT PLAN:'\n",
    "                )\n",
    "            ) as project_recommendations\n",
    "        FROM project_context pc\n",
    "    \"\"\").collect()\n",
    "    \n",
    "    if recommendations_context:\n",
    "        context = recommendations_context[0]\n",
    "        \n",
    "        st.success(f\"Project Recommendations Generated for {context['PROJECT_NAME']}\")\n",
    "        \n",
    "        # Display project info\n",
    "        col1, col2, col3 = st.columns(3)\n",
    "        with col1:\n",
    "            st.markdown(f\"**Project:** {context['PROJECT_NAME']}\")\n",
    "            st.markdown(f\"**Code:** {context['PROJECT_CODE']}\")\n",
    "        with col2:\n",
    "            st.markdown(f\"**Total Issues:** {context['TOTAL_ISSUES']}\")\n",
    "            st.markdown(f\"**Open Issues:** {context['OPEN_ISSUES']}\")\n",
    "        with col3:\n",
    "            st.markdown(f\"**Focus:** {recommendation_type}\")\n",
    "            st.markdown(f\"**Priority:** {urgency}\")\n",
    "        \n",
    "        # Display generated recommendations\n",
    "        st.markdown(\"### ðŸ”§ Generated Project Recommendations\")\n",
    "        \n",
    "        recommendations_content = context['PROJECT_RECOMMENDATIONS']\n",
    "\n",
    "        st.write(recommendations_content.strip('\"').encode().decode('unicode_escape'))\n",
    "        \n",
    "        # Make recommendations editable\n",
    "        #edited_recommendations = st.text_area(\n",
    "        #    \"Review and edit recommendations:\",\n",
    "        #    value=recommendations_content,\n",
    "        #    height=400\n",
    "        #)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000016",
   "metadata": {
    "name": "CONVERSATIONAL_ASSIST"
   },
   "source": [
    "# ðŸ¤– Conversational Manufacturing Assistant\n",
    "\n",
    "The ultimate goal is natural language interaction with our manufacturing data. Using Cortex Search, we can create a conversational assistant that answers complex operational questions, just like asking a senior manufacturing engineer.\n",
    "\n",
    "This represents the future of manufacturing intelligence - instant, contextual, and conversational.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000017",
   "metadata": {
    "language": "sql",
    "name": "cortex_search",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Create Cortex Search service for JIRA data\n",
    "-- This enables semantic search across all JIRA issues and project data\n",
    "\n",
    "CREATE OR REPLACE CORTEX SEARCH SERVICE JIRA_SEARCH\n",
    "  ON SUMMARY\n",
    "  ATTRIBUTES CREATED, PROJECT_CODE, PRIORITY, STATUS\n",
    "  WAREHOUSE = tc_wh\n",
    "  TARGET_LAG = '1 day'\n",
    "  EMBEDDING_MODEL = 'snowflake-arctic-embed-l-v2.0'\n",
    "  AS (\n",
    "    SELECT\n",
    "        i.KEY,\n",
    "        i.ID,\n",
    "        i.CREATED,\n",
    "        i.PROJECT_CODE,\n",
    "        i.PROJECT_NAME,\n",
    "        i.SUMMARY,\n",
    "        i.PRIORITY,\n",
    "        i.STATUS,\n",
    "        i.ASSIGNEE,\n",
    "        i.CREATOR,\n",
    "        i.REPORTER\n",
    "    FROM {{issues_table}} i\n",
    ");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000018",
   "metadata": {
    "language": "python",
    "name": "RAG_App"
   },
   "outputs": [],
   "source": "# Conversational JIRA Assistant\nfrom snowflake.core import Root\nfrom snowflake.cortex import complete\nimport json\n\nst.header(\"ðŸ¤– Conversational JIRA Assistant\")\nst.markdown(\"Ask natural language questions about projects, issues, and team performance.\")\n\n# Sample questions to inspire users\nst.markdown(\"\"\"\n**Try asking questions like:**\n- \"What are the most common issues in the Manufacturing Operations project?\"\n- \"What are the common themes where an electrical fault happened?\"\n- \"Which products repeatedly leak?\n\"\"\")\n\nroot = Root(session)\n\n# Conversational interface\nwith st.form(\"jira_query\"):\n    user_question = st.text_input(\n        \"Ask your JIRA question:\",\n        placeholder=\"What are the most common issues in the Manufacturing Operations project?\"\n    )\n    \n    search_submitted = st.form_submit_button(\"Search\")\n\nif search_submitted and user_question:\n    try:\n        # Search JIRA data\n        search_service = (root\n            .databases[\"ai_sol\"]\n            .schemas[\"jira\"]\n            .cortex_search_services[\"jira_search\"]\n        )\n        \n        search_results = search_service.search(\n            query=user_question,\n            columns=[\"KEY\", \"SUMMARY\", \"PROJECT_NAME\", \n                    \"PRIORITY\", \"CREATED\", \"ASSIGNEE\", \"STATUS\"],\n            limit=5\n        )\n        \n        # Generate AI response based on search results\n        model = 'claude-4-sonnet'\n        \n        context_prompt = f\"\"\"\n        Based on the following JIRA issue data, answer this question: \"{user_question}\"\n        \n        JIRA Data:\n        {search_results.to_str()}\n        \n        Provide a helpful, contextual answer that summarizes the relevant information and suggests project management actions if appropriate. \n        Be specific about issues, dates, and assignees mentioned. Focus on project insights and actionable recommendations.\n        \"\"\"\n        \n        ai_response = complete(model, context_prompt)\n        \n        st.markdown(\"### ðŸŽ¯ AI Response\")\n        st.markdown(ai_response)\n        \n        st.markdown(\"### ðŸ“‹ Relevant JIRA Issues\")\n        \n        # Display search results in a more readable format\n        results_json_string = search_results.to_json()  \n        results_data = json.loads(results_json_string)  \n        \n        if results_data and 'results' in results_data:\n            for i, result in enumerate(results_data['results'][:3]):  # Show top 3\n                with st.expander(f\"ðŸŽ« {result.get('KEY', 'Unknown Issue')} - {result.get('PRIORITY', 'Normal')} Priority\"):\n                    st.markdown(f\"**Project:** {result.get('PROJECT_NAME', 'N/A')}\")\n                    st.markdown(f\"**Created:** {result.get('CREATED', 'N/A')}\")\n                    st.markdown(f\"**Assignee:** {result.get('ASSIGNEE', 'N/A')}\")\n                    st.markdown(f\"**Status:** {result.get('STATUS', 'N/A')}\")\n                    st.markdown(f\"**Summary:** {result.get('SUMMARY', 'No summary available')}\")\n        \n    except Exception as e:\n        st.error(f\"Error: {str(e)}\")\n        st.info(\"Note: Make sure the JIRA_SEARCH service has been created and is available.\")\n"
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000019",
   "metadata": {
    "name": "AI_for_BI"
   },
   "source": [
    "# ðŸ“Š AI for Manufacturing Business Intelligence\n",
    "\n",
    "## ðŸŽ¯ Purpose\n",
    "Learn how to leverage Snowflake's AI capabilities for advanced manufacturing intelligence through semantic analysis.\n",
    "\n",
    "## ðŸ”‘ Key Components\n",
    "\n",
    "- **Analyst Tool**: Enables quantitative analysis through natural language queries\n",
    "- **Data Semantics**: Ensures accuracy and consistency in analysis through defined relationships and metrics\n",
    "- **Semantic Views**: Can be created through:\n",
    "  - UI-based configuration in Snowflake interface\n",
    "  - SQL-based definition (demonstrated in next cell)\n",
    "\n",
    "## ðŸ’¡ Benefits\n",
    "- Natural language querying of your manufacturing data\n",
    "- Consistent metric definitions across your organization\n",
    "- Enhanced data discoverability and understanding\n",
    "- Improved data governance through semantic layer\n",
    "- Real-time operational insights and predictive analytics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000020",
   "metadata": {
    "codeCollapsed": false,
    "language": "sql",
    "name": "semantic_views",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "CREATE\n",
    "OR REPLACE SEMANTIC VIEW jira_analytics \n",
    "TABLES (\n",
    "  issues AS AI_SOL.JIRA.ISSUES PRIMARY KEY (KEY) WITH SYNONYMS ('tickets', 'problems', 'tasks', 'bugs') COMMENT = 'JIRA issues and tickets information',\n",
    "  metadata AS AI_SOL.JIRA.JIRA_ISSUE_METADATA PRIMARY KEY (ISSUE_KEY) WITH SYNONYMS ('issue metadata', 'extracted data', 'ai insights') COMMENT = 'AI-extracted metadata and insights from JIRA issues',\n",
    "  projects AS AI_SOL.JIRA.PROJECTS PRIMARY KEY (PROJECT_CODE) WITH SYNONYMS ('project', 'initiatives') COMMENT = 'JIRA project configurations and details',\n",
    "  users AS AI_SOL.JIRA.USERS PRIMARY KEY (DISPLAY_NAME) WITH SYNONYMS ('people', 'team members', 'assignees') COMMENT = 'JIRA users and team member information'\n",
    ") \n",
    "RELATIONSHIPS (\n",
    "  issues_to_metadata AS issues (KEY) REFERENCES metadata (ISSUE_KEY),\n",
    "  issues_to_projects AS issues (PROJECT_CODE) REFERENCES projects (PROJECT_CODE),\n",
    "  issues_to_assignee AS issues (ASSIGNEE) REFERENCES users (DISPLAY_NAME),\n",
    "  issues_to_creator AS issues (CREATOR) REFERENCES users (DISPLAY_NAME),\n",
    "  issues_to_reporter AS issues (REPORTER) REFERENCES users (DISPLAY_NAME)\n",
    ") \n",
    "FACTS (\n",
    "  issues.resolution_hours AS DATEDIFF (hour, issues.CREATED, issues.RESOLVED_TS),\n",
    "  issues.issue_count AS 1 COMMENT = 'Count of individual issues',\n",
    "  metadata.downtime_minutes AS metadata.DOWNTIME_MINUTES COMMENT = 'Production downtime in minutes'\n",
    ") \n",
    "DIMENSIONS (\n",
    "  issues.key AS KEY WITH SYNONYMS ('ticket key', 'issue number') COMMENT = 'Unique JIRA issue key',\n",
    "  issues.summary AS SUMMARY WITH SYNONYMS ('title', 'description', 'issue summary') COMMENT = 'Brief description of the issue',\n",
    "  issues.priority AS PRIORITY WITH SYNONYMS ('urgency', 'severity', 'importance') COMMENT = 'Priority level of the issue',\n",
    "  issues.status AS STATUS WITH SYNONYMS ('state', 'condition', 'stage') COMMENT = 'Current status of the issue',\n",
    "  issues.status_category AS STATUS_CATEGORY WITH SYNONYMS ('status group', 'category') COMMENT = 'Category grouping of status',\n",
    "  issues.created AS CREATED COMMENT = 'Date when issue was created',\n",
    "  issues.resolved_ts AS RESOLVED_TS COMMENT = 'Date when issue was resolved',\n",
    "  issues.assignee AS ASSIGNEE WITH SYNONYMS ('assigned to', 'owner') COMMENT = 'Person assigned to the issue',\n",
    "  issues.creator AS CREATOR WITH SYNONYMS ('created by', 'author') COMMENT = 'Person who created the issue',\n",
    "  issues.reporter AS REPORTER WITH SYNONYMS ('reported by') COMMENT = 'Person who reported the issue',\n",
    "  issues.channel AS CHANNEL WITH SYNONYMS ('source', 'origin') COMMENT = 'Channel through which issue was reported',\n",
    "  issues.labels AS LABELS WITH SYNONYMS ('tags', 'categories') COMMENT = 'Labels or tags associated with the issue',\n",
    "  metadata.equipment_name AS EQUIPMENT_NAME WITH SYNONYMS ('asset', 'machine', 'equipment') COMMENT = 'Equipment or asset involved in the issue',\n",
    "  metadata.failure_type AS FAILURE_TYPE WITH SYNONYMS ('failure mode', 'issue type', 'problem type') COMMENT = 'Type of failure or malfunction',\n",
    "  metadata.component_affected AS COMPONENT_AFFECTED WITH SYNONYMS ('part', 'component', 'failed part') COMMENT = 'Specific component that failed',\n",
    "  metadata.production_line AS PRODUCTION_LINE WITH SYNONYMS ('line', 'manufacturing line') COMMENT = 'Production line where issue occurred',\n",
    "  metadata.plant_location AS PLANT_LOCATION WITH SYNONYMS ('plant', 'facility', 'location') COMMENT = 'Plant or facility location',\n",
    "  metadata.urgency_level AS URGENCY_LEVEL WITH SYNONYMS ('urgency', 'criticality') COMMENT = 'AI-classified urgency level',\n",
    "  metadata.department AS DEPARTMENT WITH SYNONYMS ('responsible team', 'routing') COMMENT = 'Department responsible for resolution',\n",
    "  metadata.sentiment AS SENTIMENT WITH SYNONYMS ('tone', 'sentiment analysis') COMMENT = 'Sentiment analysis of issue',\n",
    "  metadata.action_flag AS ACTION_FLAG WITH SYNONYMS ('action required', 'flag', 'alert') COMMENT = 'Action flag for special handling',\n",
    "  metadata.requires_parts AS REQUIRES_PARTS COMMENT = 'Whether parts are required for resolution',\n",
    "  metadata.safety_concern AS SAFETY_CONCERN WITH SYNONYMS ('safety issue', 'compliance') COMMENT = 'Whether issue has safety implications',\n",
    "  projects.project_code AS PROJECT_CODE WITH SYNONYMS ('project key', 'code') COMMENT = 'Unique project identifier',\n",
    "  projects.project_name AS PROJECT_NAME WITH SYNONYMS ('project title', 'name') COMMENT = 'Name of the project',\n",
    "  users.display_name AS DISPLAY_NAME WITH SYNONYMS ('name', 'person') COMMENT = 'Display name of the user',\n",
    "  users.role AS ROLE WITH SYNONYMS ('position', 'job title') COMMENT = 'Role or position of the user',\n",
    "  users.team AS TEAM WITH SYNONYMS ('department', 'group') COMMENT = 'Team or department of the user',\n",
    "  users.location AS LOCATION WITH SYNONYMS ('office', 'site') COMMENT = 'Location of the user'\n",
    ") \n",
    "METRICS (\n",
    "  issues.total_issues AS COUNT(issues.KEY) COMMENT = 'Total number of issues',\n",
    "  issues.resolved_issues AS COUNT(\n",
    "    CASE\n",
    "      WHEN issues.RESOLVED_TS IS NOT NULL THEN issues.KEY\n",
    "      ELSE NULL\n",
    "    END\n",
    "  ) COMMENT = 'Number of resolved issues',\n",
    "  issues.open_issues AS COUNT(\n",
    "    CASE\n",
    "      WHEN issues.STATUS IN ('Open', 'In Progress', 'To Do') THEN issues.KEY\n",
    "      ELSE NULL\n",
    "    END\n",
    "  ) COMMENT = 'Number of open issues',\n",
    "  issues.avg_resolution_time AS AVG(issues.resolution_hours) COMMENT = 'Average time to resolve issues in hours',\n",
    "  issues.critical_issues AS COUNT(\n",
    "    CASE\n",
    "      WHEN issues.PRIORITY = 'Critical' THEN issues.KEY\n",
    "      ELSE NULL\n",
    "    END\n",
    "  ) COMMENT = 'Number of critical priority issues',\n",
    "  issues.high_priority_issues AS COUNT(\n",
    "    CASE\n",
    "      WHEN issues.PRIORITY IN ('Critical', 'High') THEN issues.KEY\n",
    "      ELSE NULL\n",
    "    END\n",
    "  ) COMMENT = 'Number of high priority issues',\n",
    "  metadata.total_downtime AS SUM(metadata.DOWNTIME_MINUTES) COMMENT = 'Total production downtime in minutes',\n",
    "  metadata.avg_downtime AS AVG(metadata.DOWNTIME_MINUTES) COMMENT = 'Average downtime per issue in minutes',\n",
    "  metadata.safety_issues AS COUNT(\n",
    "    CASE\n",
    "      WHEN metadata.SAFETY_CONCERN = TRUE THEN metadata.ISSUE_KEY\n",
    "      ELSE NULL\n",
    "    END\n",
    "  ) COMMENT = 'Number of issues with safety concerns',\n",
    "  metadata.parts_required_issues AS COUNT(\n",
    "    CASE\n",
    "      WHEN metadata.REQUIRES_PARTS = TRUE THEN metadata.ISSUE_KEY\n",
    "      ELSE NULL\n",
    "    END\n",
    "  ) COMMENT = 'Number of issues requiring parts',\n",
    "  metadata.critical_action_issues AS COUNT(\n",
    "    CASE\n",
    "      WHEN metadata.ACTION_FLAG = 'Immediate Action Required' THEN metadata.ISSUE_KEY\n",
    "      ELSE NULL\n",
    "    END\n",
    "  ) COMMENT = 'Number of issues requiring immediate action',\n",
    "  projects.total_projects AS COUNT(DISTINCT projects.PROJECT_CODE) COMMENT = 'Total number of projects',\n",
    "  issues.issues_per_project AS COUNT(issues.KEY) / COUNT(DISTINCT issues.PROJECT_CODE) COMMENT = 'Average issues per project',\n",
    "  users.total_users AS COUNT(DISTINCT users.DISPLAY_NAME) COMMENT = 'Total number of users',\n",
    "  issues.issues_per_assignee AS COUNT(issues.KEY) / COUNT(DISTINCT issues.ASSIGNEE) COMMENT = 'Average issues per assignee',\n",
    "  issues.resolution_rate AS (\n",
    "    COUNT(\n",
    "      CASE\n",
    "        WHEN issues.RESOLVED_TS IS NOT NULL THEN issues.KEY\n",
    "      END\n",
    "    ) * 100.0 / COUNT(issues.KEY)\n",
    "  ) COMMENT = 'Percentage of issues that have been resolved',\n",
    "  issues.sla_compliance AS (\n",
    "    COUNT(\n",
    "      CASE\n",
    "        WHEN issues.RESOLVED_TS IS NOT NULL\n",
    "        AND DATEDIFF (hour, issues.CREATED, issues.RESOLVED_TS) <= 24 THEN issues.KEY\n",
    "      END\n",
    "    ) * 100.0 / COUNT(\n",
    "      CASE\n",
    "        WHEN issues.RESOLVED_TS IS NOT NULL THEN issues.KEY\n",
    "      END\n",
    "    )\n",
    "  ) COMMENT = 'Percentage of issues resolved within 24 hours'\n",
    ") COMMENT = 'Comprehensive semantic view for JIRA analytics with AI-extracted metadata for enhanced manufacturing intelligence';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000021",
   "metadata": {
    "language": "sql",
    "name": "sql_semantics",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": "-- Semantic views can be used by AI features (Analyst & Intelligence)\n-- or BI tools via SELECT *.. for example\n-- This example shows project performance with AI-extracted manufacturing insights\n\nSELECT * FROM SEMANTIC_VIEW(\n    jira_analytics  \n    DIMENSIONS projects.project_name, issues.priority, metadata.equipment_name, metadata.failure_type\n    METRICS issues.total_issues, issues.resolved_issues, issues.avg_resolution_time, metadata.total_downtime, metadata.safety_issues\n  );\n  \n-- Example: Analyze downtime by equipment and failure type\nSELECT * FROM SEMANTIC_VIEW(\n    jira_analytics\n    DIMENSIONS metadata.equipment_name, metadata.failure_type, metadata.plant_location\n    METRICS issues.total_issues, metadata.avg_downtime, metadata.total_downtime\n  )\n  WHERE metadata.equipment_name IS NOT NULL\n  ORDER BY metadata.total_downtime DESC;\n"
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000022",
   "metadata": {
    "name": "time_to_create_agents"
   },
   "source": [
    "# ðŸš€ Next Steps: From Demo to Production\n",
    "\n",
    "Congratulations! You've experienced the power of AI-driven manufacturing intelligence. Here's how to take this from demo to production:\n",
    "\n",
    "## 1. ðŸŽ¯ **Deploy Manufacturing Assistant**\n",
    "Integrate the search service and AI capabilities into your CMMS or create a standalone Streamlit application for your maintenance teams.\n",
    "\n",
    "## 2. ðŸ“Š **Expand Semantic Views**\n",
    "Head to **AI > Studio > Cortex Analyst** to create and update semantic views of your manufacturing data, enabling natural language reporting and self-service analytics.\n",
    "\n",
    "## 3. ðŸ¤– **Build Manufacturing Agents**\n",
    "Use the search services and AI functions as tools for intelligent agents that can:\n",
    "- Automatically generate maintenance plans\n",
    "- Monitor equipment health in real-time\n",
    "- Predict failures before they occur\n",
    "- Optimize maintenance schedules\n",
    "\n",
    "## 4. ðŸ”„ **Integrate with Your Systems**\n",
    "Connect these AI capabilities directly to your CMMS, ERP, or existing manufacturing systems through APIs for seamless workflow integration.\n",
    "\n",
    "## 5. ðŸ“ˆ **Scale Across Manufacturing Operations**\n",
    "Roll out to your entire manufacturing organization with:\n",
    "- Plant-specific insights\n",
    "- Equipment expertise augmentation  \n",
    "- Automated maintenance recommendations\n",
    "- Real-time operational intelligence\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ’¡ **Key Takeaways**\n",
    "\n",
    "âœ… **Conversational AI** transforms how maintenance teams interact with operational data\n",
    "\n",
    "âœ… **Automated Intelligence** surfaces insights that would take hours to find manually\n",
    "\n",
    "âœ… **Predictive Recommendations** help teams take proactive action before failures occur\n",
    "\n",
    "âœ… **Root Cause Awareness** keeps teams ahead of recurring problems\n",
    "\n",
    "âœ… **Maintenance Automation** ensures consistent processes across all equipment\n",
    "\n",
    "---\n",
    "\n",
    "*Ready to revolutionize your manufacturing intelligence? Start with your own JIRA data and see the transformation firsthand.*\n"
   ]
  }
 ]
}